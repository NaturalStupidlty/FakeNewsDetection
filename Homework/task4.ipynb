{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "f3819e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import pygame\n",
    "from functools import reduce\n",
    "from tqdm import tqdm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# NLP\n",
    "import re\n",
    "import gensim\n",
    "import nltk\n",
    "import spacy\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "from pymystem3 import Mystem\n",
    "from string import punctuation\n",
    "from spacy.tokenizer import Tokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import tokenize\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Sklearn\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import roc_auc_score, precision_score, recall_score\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import StratifiedKFold, RepeatedStratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "153ae9d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gpu for mac m1\n",
    "mps_device = torch.device(\"mps\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "be7c7c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"../data/jigsaw-toxic-comment-classification-challenge/train.csv\")\n",
    "test = pd.read_csv(\"../data/jigsaw-toxic-comment-classification-challenge/test.csv\")\n",
    "test_labels = pd.read_csv(\"../data/jigsaw-toxic-comment-classification-challenge/test_labels.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "801bd718",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000997932d777bf</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000103f0d9cfb60f</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000113f07ec002fd</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0001b41b1c6bb37e</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0001d958c54c6e35</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                       comment_text  toxic  \\\n",
       "0  0000997932d777bf  Explanation\\nWhy the edits made under my usern...      0   \n",
       "1  000103f0d9cfb60f  D'aww! He matches this background colour I'm s...      0   \n",
       "2  000113f07ec002fd  Hey man, I'm really not trying to edit war. It...      0   \n",
       "3  0001b41b1c6bb37e  \"\\nMore\\nI can't make any real suggestions on ...      0   \n",
       "4  0001d958c54c6e35  You, sir, are my hero. Any chance you remember...      0   \n",
       "\n",
       "   severe_toxic  obscene  threat  insult  identity_hate  \n",
       "0             0        0       0       0              0  \n",
       "1             0        0       0       0              0  \n",
       "2             0        0       0       0              0  \n",
       "3             0        0       0       0              0  \n",
       "4             0        0       0       0              0  "
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "e6ad96c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_columns = [\"toxic\", \"severe_toxic\",\n",
    "                  \"obscene\", \"threat\",\n",
    "                  \"insult\", \"identity_hate\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "0c75b2d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test.merge(test_labels, on=\"id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "0194a92a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00001cee341fdb12</td>\n",
       "      <td>Yo bitch Ja Rule is more succesful then you'll...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0000247867823ef7</td>\n",
       "      <td>== From RfC == \\n\\n The title is fine as it is...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00013b17ad220c46</td>\n",
       "      <td>\" \\n\\n == Sources == \\n\\n * Zawe Ashton on Lap...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00017563c3f7919a</td>\n",
       "      <td>:If you have a look back at the source, the in...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00017695ad8997eb</td>\n",
       "      <td>I don't anonymously edit articles at all.</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                       comment_text  toxic  \\\n",
       "0  00001cee341fdb12  Yo bitch Ja Rule is more succesful then you'll...     -1   \n",
       "1  0000247867823ef7  == From RfC == \\n\\n The title is fine as it is...     -1   \n",
       "2  00013b17ad220c46  \" \\n\\n == Sources == \\n\\n * Zawe Ashton on Lap...     -1   \n",
       "3  00017563c3f7919a  :If you have a look back at the source, the in...     -1   \n",
       "4  00017695ad8997eb          I don't anonymously edit articles at all.     -1   \n",
       "\n",
       "   severe_toxic  obscene  threat  insult  identity_hate  \n",
       "0            -1       -1      -1      -1             -1  \n",
       "1            -1       -1      -1      -1             -1  \n",
       "2            -1       -1      -1      -1             -1  \n",
       "3            -1       -1      -1      -1             -1  \n",
       "4            -1       -1      -1      -1             -1  "
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "2caa5c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "closed_test = test[(test[target_columns] == -1).any(axis=1)].reset_index(drop=True)\n",
    "test = test[~(test[target_columns] == -1).any(axis=1)].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "976a08f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id               0\n",
      "comment_text     0\n",
      "toxic            0\n",
      "severe_toxic     0\n",
      "obscene          0\n",
      "threat           0\n",
      "insult           0\n",
      "identity_hate    0\n",
      "dtype: int64 \n",
      "\n",
      "id               0\n",
      "comment_text     0\n",
      "toxic            0\n",
      "severe_toxic     0\n",
      "obscene          0\n",
      "threat           0\n",
      "insult           0\n",
      "identity_hate    0\n",
      "dtype: int64 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for data in [train, test]:\n",
    "    print(train.isnull().sum(), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "80267740",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train\n",
      "0    0.904156\n",
      "1    0.095844\n",
      "Name: toxic, dtype: float64\n",
      "0    0.990004\n",
      "1    0.009996\n",
      "Name: severe_toxic, dtype: float64\n",
      "0    0.947052\n",
      "1    0.052948\n",
      "Name: obscene, dtype: float64\n",
      "0    0.997004\n",
      "1    0.002996\n",
      "Name: threat, dtype: float64\n",
      "0    0.950636\n",
      "1    0.049364\n",
      "Name: insult, dtype: float64\n",
      "0    0.991195\n",
      "1    0.008805\n",
      "Name: identity_hate, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(\"Train\")\n",
    "for col in target_columns:\n",
    "    print(train[col].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "d94a092a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test\n",
      "0    0.904811\n",
      "1    0.095189\n",
      "Name: toxic, dtype: float64\n",
      "0    0.994264\n",
      "1    0.005736\n",
      "Name: severe_toxic, dtype: float64\n",
      "0    0.942308\n",
      "1    0.057692\n",
      "Name: obscene, dtype: float64\n",
      "0    0.996702\n",
      "1    0.003298\n",
      "Name: threat, dtype: float64\n",
      "0    0.946435\n",
      "1    0.053565\n",
      "Name: insult, dtype: float64\n",
      "0    0.988871\n",
      "1    0.011129\n",
      "Name: identity_hate, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(\"Test\")\n",
    "for col in target_columns:\n",
    "    print(test[col].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "b2de93a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = stopwords.words('english')\n",
    "stop_words.extend(['from', 'subject', 're', 'edu', 'use'])\n",
    "mystem = Mystem()\n",
    "\n",
    "def preprocess(text, stemming=True):\n",
    "    if stemming:\n",
    "        tokens = mystem.lemmatize(text.lower())\n",
    "        tokens = [token for token in tokens if token not in stop_words\\\n",
    "                  and token != \" \"\\\n",
    "                  and token.strip() not in punctuation]\n",
    "    else:\n",
    "        tokens = gensim.utils.simple_preprocess(text)\n",
    "        tokens = [token for token in tokens if (token not in\\\n",
    "                    gensim.parsing.preprocessing.STOPWORDS and \n",
    "                    token not in stop_words)]\n",
    "        \n",
    "    text = \" \".join(tokens)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "2afbda8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collapse_dots(input):\n",
    "    # Collapse sequential dots\n",
    "    input = re.sub(\"\\.+\", \".\", input)\n",
    "    # Collapse dots separated by whitespaces\n",
    "    all_collapsed = False\n",
    "    while not all_collapsed:\n",
    "        output = re.sub(r\"\\.(( )*)\\.\", \".\", input)\n",
    "        all_collapsed = input == output\n",
    "        input = output\n",
    "    return output\n",
    "\n",
    "def process_text(input):\n",
    "    if isinstance(input, str):\n",
    "        input = \" \".join(tokenize.sent_tokenize(input))\n",
    "        input = re.sub(r\"http\\S+\", \"\", input)\n",
    "        input = re.sub(r\"\\n+\", \". \", input)\n",
    "        for symb in [\"!\", \",\", \":\", \";\", \"?\"]:\n",
    "            input = re.sub(rf\"\\{symb}\\.\", symb, input)\n",
    "        input = re.sub(\"[^а-яА-Яa-zA-Z0-9!\\\"#$%&'()*+,-./:;<=>?@[\\\\]^_`{|}~ё]+\", \" \", input)\n",
    "        input = re.sub(r\"#\\S+\", \"\", input)\n",
    "        input = collapse_dots(input)\n",
    "        input = input.strip()\n",
    "        # input = input.lower()\n",
    "    return input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a93374b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train['comment_text'] = train['comment_text'].apply(preprocess, False)\n",
    "#test['comment_text'] = test['comment_text'].apply(preprocess, False)\n",
    "\n",
    "sent_tr = SentenceTransformer('all-MiniLM-L6-v2', device=\"mps\")\n",
    "train['light_clean_comment_text'] = train['comment_text'].apply(process_text)\n",
    "test['light_clean_comment_text'] = test['comment_text'].apply(process_text)\n",
    "train_embs = sent_tr.encode(train[\"light_clean_comment_text\"].to_list())\n",
    "test_embs = sent_tr.encode(test[\"light_clean_comment_text\"].to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fad088e",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "model = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"lof_reg\", MultiOutputClassifier(LogisticRegression()))\n",
    "])\n",
    "\n",
    "all_train_pred = model.fit(\n",
    "    train_embs, \n",
    "    train[target_columns]\n",
    ").predict_proba(train_embs)\n",
    "all_train_pred = np.stack([el[:,1] for el in all_train_pred],axis=1)\n",
    "compute_metric(train[target_columns].values, all_train_pred)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1a21a92f",
   "metadata": {},
   "outputs": [],
   "source": [
    "FOLDS = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "85dbe8e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "000000    143346\n",
       "100000      5666\n",
       "101010      3800\n",
       "101000      1758\n",
       "100010      1215\n",
       "111010       989\n",
       "101011       618\n",
       "001000       317\n",
       "000010       301\n",
       "111011       265\n",
       "001010       181\n",
       "111000       158\n",
       "100001       136\n",
       "100011       134\n",
       "101110       131\n",
       "100100       113\n",
       "111110        64\n",
       "101111        56\n",
       "000001        54\n",
       "-1            42\n",
       "110000        41\n",
       "101001        35\n",
       "111111        31\n",
       "000011        28\n",
       "000100        22\n",
       "001011        18\n",
       "100110        16\n",
       "110010        14\n",
       "101100        11\n",
       "110100        11\n",
       "Name: stratified_target, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[\"stratified_target\"] = train[target_columns].apply(\n",
    "    lambda x: reduce(lambda x, y: str(x) + str(y), x), axis=1)\n",
    "\n",
    "small_groups = train[\"stratified_target\"].value_counts()[\n",
    "    train[\"stratified_target\"].value_counts() < FOLDS].index\n",
    "\n",
    "train.loc[train[\"stratified_target\"].isin(small_groups), \"stratified_target\"] = \"-1\"\n",
    "train[\"stratified_target\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1be9e4c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metric(y_true, y_pred, verbose=True):\n",
    "    assert y_true.shape == y_pred.shape\n",
    "    roc_aucs = [roc_auc_score(y_true[:,i], y_pred[:,i]) for i in range(y_pred.shape[1])]\n",
    "    if verbose:\n",
    "        for metric, col in zip(roc_aucs, target_columns):\n",
    "            print(f\"{col} Roc Auc: {metric}\")\n",
    "        print(f\"Result Roc Auc: {np.mean(roc_aucs)}\")\n",
    "    return roc_aucs, np.mean(roc_aucs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b72e7091",
   "metadata": {},
   "outputs": [],
   "source": [
    "stratifier = StratifiedKFold(n_splits=FOLDS, random_state=69, shuffle=True)\n",
    "classifier = MultiOutputClassifier(LogisticRegression(max_iter=1000))\n",
    "#vectorizer = CountVectorizer()\n",
    "#vectorizer = CountVectorizer(ngram_range=(1,2))\n",
    "vectorizer = TfidfVectorizer()\n",
    "#spacy_nlp = spacy.load('ru_core_news_md')\n",
    "#vectorizer = CountVectorizer(token_pattern = None, tokenizer=Tokenizer(spacy_nlp.vocab))\n",
    "\n",
    "pipeline = Pipeline([(\"vectorizer\", vectorizer),\n",
    "         (\"classifier\", classifier)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fd3eeba1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def fit_ensemble(X, y, stratifier, pipeline, verbose=True):\n",
    "    all_train_preds = []\n",
    "    all_test_preds = []\n",
    "    all_train_targets = []\n",
    "    all_test_targets = []\n",
    "    all_models = []\n",
    "    \n",
    "    folds_ids = [el for el in stratifier.split(train, train[\"stratified_target\"])]\n",
    "    \n",
    "    start = time.time()\n",
    "    for fold_id, (train_ids, test_ids) in enumerate(folds_ids):\n",
    "        model = pipeline\n",
    "        model.fit(X.iloc[train_ids], y.iloc[train_ids])\n",
    "\n",
    "        fold_train_preds = model.predict_proba(X.iloc[train_ids])\n",
    "        fold_train_preds = np.stack([el[:,1] for el in fold_train_preds],axis=1)\n",
    "        fold_test_preds = model.predict_proba(X.iloc[test_ids])\n",
    "        fold_test_preds = np.stack([el[:,1] for el in fold_test_preds],axis=1)\n",
    "        fold_train_targets = y.iloc[train_ids].values\n",
    "        fold_test_targets = y.iloc[test_ids].values\n",
    "\n",
    "        if verbose:\n",
    "            print(f\"Fold {fold_id + 1}\")\n",
    "            print(\"Train ROC AUC: \")\n",
    "            compute_metric(fold_train_targets, fold_train_preds)\n",
    "            print(\"Test: ROC AUC\")\n",
    "            compute_metric(fold_test_targets, fold_test_preds)\n",
    "        \n",
    "        all_train_preds.append(fold_train_preds)\n",
    "        all_test_preds.append(fold_test_preds)\n",
    "        all_train_targets.append(fold_train_targets)\n",
    "        all_test_targets.append(fold_test_targets)\n",
    "        all_models.append(model)\n",
    "\n",
    "    stop = time.time()\n",
    "    print('Training time (mins):', np.round((stop - start) / 60, 2))\n",
    "    \n",
    "    return [(all_train_preds, all_test_preds),\n",
    "            (all_train_targets, all_test_targets),\n",
    "            all_models]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fd033a81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1\n",
      "Train ROC AUC: \n",
      "toxic Roc Auc: 0.9852448375004742\n",
      "severe_toxic Roc Auc: 0.9929108822616101\n",
      "obscene Roc Auc: 0.994041892902537\n",
      "threat Roc Auc: 0.9956395784291873\n",
      "insult Roc Auc: 0.9883784309864068\n",
      "identity_hate Roc Auc: 0.9908197386602857\n",
      "Result Roc Auc: 0.9911725601234168\n",
      "Test: ROC AUC\n",
      "toxic Roc Auc: 0.969692608790554\n",
      "severe_toxic Roc Auc: 0.9830335762851099\n",
      "obscene Roc Auc: 0.9818376389989006\n",
      "threat Roc Auc: 0.9690501634397787\n",
      "insult Roc Auc: 0.9758345609865234\n",
      "identity_hate Roc Auc: 0.982196449183752\n",
      "Result Roc Auc: 0.9769408329474366\n",
      "Fold 2\n",
      "Train ROC AUC: \n",
      "toxic Roc Auc: 0.9853737282823443\n",
      "severe_toxic Roc Auc: 0.9927904851983059\n",
      "obscene Roc Auc: 0.9936844322930746\n",
      "threat Roc Auc: 0.9951146191916749\n",
      "insult Roc Auc: 0.9881795857410176\n",
      "identity_hate Roc Auc: 0.990930307923918\n",
      "Result Roc Auc: 0.991012193105056\n",
      "Test: ROC AUC\n",
      "toxic Roc Auc: 0.9675042333751518\n",
      "severe_toxic Roc Auc: 0.987281550954798\n",
      "obscene Roc Auc: 0.9845121291004908\n",
      "threat Roc Auc: 0.9860458429731066\n",
      "insult Roc Auc: 0.9771412140643505\n",
      "identity_hate Roc Auc: 0.9762136933518049\n",
      "Result Roc Auc: 0.979783110636617\n",
      "Fold 3\n",
      "Train ROC AUC: \n",
      "toxic Roc Auc: 0.985327651520763\n",
      "severe_toxic Roc Auc: 0.9928966560359588\n",
      "obscene Roc Auc: 0.9936524363117055\n",
      "threat Roc Auc: 0.9953083611682758\n",
      "insult Roc Auc: 0.9880344777541142\n",
      "identity_hate Roc Auc: 0.9911542656598282\n",
      "Result Roc Auc: 0.9910623080751075\n",
      "Test: ROC AUC\n",
      "toxic Roc Auc: 0.9700630393125538\n",
      "severe_toxic Roc Auc: 0.9835520589352409\n",
      "obscene Roc Auc: 0.986093217518965\n",
      "threat Roc Auc: 0.97578452151757\n",
      "insult Roc Auc: 0.979131260370607\n",
      "identity_hate Roc Auc: 0.9747647758189987\n",
      "Result Roc Auc: 0.9782314789123226\n",
      "Fold 4\n",
      "Train ROC AUC: \n",
      "toxic Roc Auc: 0.9852741348282167\n",
      "severe_toxic Roc Auc: 0.9928486279497595\n",
      "obscene Roc Auc: 0.9937028962875348\n",
      "threat Roc Auc: 0.9951314469405018\n",
      "insult Roc Auc: 0.9882029990798106\n",
      "identity_hate Roc Auc: 0.9907800609928354\n",
      "Result Roc Auc: 0.9909900276797764\n",
      "Test: ROC AUC\n",
      "toxic Roc Auc: 0.9712761030936322\n",
      "severe_toxic Roc Auc: 0.9867866933841258\n",
      "obscene Roc Auc: 0.986785012787748\n",
      "threat Roc Auc: 0.9852117200156416\n",
      "insult Roc Auc: 0.9769171255742193\n",
      "identity_hate Roc Auc: 0.9757695715869673\n",
      "Result Roc Auc: 0.9804577044070557\n",
      "Fold 5\n",
      "Train ROC AUC: \n",
      "toxic Roc Auc: 0.9853108718236411\n",
      "severe_toxic Roc Auc: 0.9929968788192886\n",
      "obscene Roc Auc: 0.9937620445690329\n",
      "threat Roc Auc: 0.9951333744415267\n",
      "insult Roc Auc: 0.9883984975704175\n",
      "identity_hate Roc Auc: 0.9907747884737654\n",
      "Result Roc Auc: 0.9910627426162787\n",
      "Test: ROC AUC\n",
      "toxic Roc Auc: 0.9695483327098315\n",
      "severe_toxic Roc Auc: 0.9825358038315494\n",
      "obscene Roc Auc: 0.9853075629624913\n",
      "threat Roc Auc: 0.9817049326853248\n",
      "insult Roc Auc: 0.973170636212714\n",
      "identity_hate Roc Auc: 0.9731787004451906\n",
      "Result Roc Auc: 0.9775743281411836\n",
      "Fold 6\n",
      "Train ROC AUC: \n",
      "toxic Roc Auc: 0.9851693166627865\n",
      "severe_toxic Roc Auc: 0.9927950570438998\n",
      "obscene Roc Auc: 0.9938094271505318\n",
      "threat Roc Auc: 0.9952305473912897\n",
      "insult Roc Auc: 0.9880884577821186\n",
      "identity_hate Roc Auc: 0.9910835828742669\n",
      "Result Roc Auc: 0.9910293981508155\n",
      "Test: ROC AUC\n",
      "toxic Roc Auc: 0.9727488090430949\n",
      "severe_toxic Roc Auc: 0.988433413106582\n",
      "obscene Roc Auc: 0.9848310132470454\n",
      "threat Roc Auc: 0.9787371404027071\n",
      "insult Roc Auc: 0.9789896452703808\n",
      "identity_hate Roc Auc: 0.9753730399595346\n",
      "Result Roc Auc: 0.9798521768382241\n",
      "Fold 7\n",
      "Train ROC AUC: \n",
      "toxic Roc Auc: 0.9851926179184849\n",
      "severe_toxic Roc Auc: 0.9927822430790628\n",
      "obscene Roc Auc: 0.9937571016010726\n",
      "threat Roc Auc: 0.9951786463733767\n",
      "insult Roc Auc: 0.9881201879736878\n",
      "identity_hate Roc Auc: 0.9906708899663426\n",
      "Result Roc Auc: 0.9909502811520046\n",
      "Test: ROC AUC\n",
      "toxic Roc Auc: 0.972740581635556\n",
      "severe_toxic Roc Auc: 0.9879374676012983\n",
      "obscene Roc Auc: 0.984858813886773\n",
      "threat Roc Auc: 0.982634305529365\n",
      "insult Roc Auc: 0.9780075741471606\n",
      "identity_hate Roc Auc: 0.981218633074685\n",
      "Result Roc Auc: 0.9812328959791397\n",
      "Fold 8\n",
      "Train ROC AUC: \n",
      "toxic Roc Auc: 0.9854257269859041\n",
      "severe_toxic Roc Auc: 0.9927815480511764\n",
      "obscene Roc Auc: 0.9937350706335181\n",
      "threat Roc Auc: 0.9951669545838332\n",
      "insult Roc Auc: 0.9882267086161713\n",
      "identity_hate Roc Auc: 0.991108969159132\n",
      "Result Roc Auc: 0.9910741630049559\n",
      "Test: ROC AUC\n",
      "toxic Roc Auc: 0.9704260509731186\n",
      "severe_toxic Roc Auc: 0.9877612026398082\n",
      "obscene Roc Auc: 0.9860453387879378\n",
      "threat Roc Auc: 0.978118998133643\n",
      "insult Roc Auc: 0.975652880144938\n",
      "identity_hate Roc Auc: 0.9722900147450633\n",
      "Result Roc Auc: 0.9783824142374181\n",
      "Fold 9\n",
      "Train ROC AUC: \n",
      "toxic Roc Auc: 0.9853164559129126\n",
      "severe_toxic Roc Auc: 0.992899190628818\n",
      "obscene Roc Auc: 0.9936844238057964\n",
      "threat Roc Auc: 0.9951021845424192\n",
      "insult Roc Auc: 0.9882006507408876\n",
      "identity_hate Roc Auc: 0.9907384750989802\n",
      "Result Roc Auc: 0.9909902301216357\n",
      "Test: ROC AUC\n",
      "toxic Roc Auc: 0.9704645135367372\n",
      "severe_toxic Roc Auc: 0.9849421510924776\n",
      "obscene Roc Auc: 0.9862459877286331\n",
      "threat Roc Auc: 0.9913084419083199\n",
      "insult Roc Auc: 0.9769239596307498\n",
      "identity_hate Roc Auc: 0.9759991810390191\n",
      "Result Roc Auc: 0.9809807058226562\n",
      "Fold 10\n",
      "Train ROC AUC: \n",
      "toxic Roc Auc: 0.9853317491076994\n",
      "severe_toxic Roc Auc: 0.9927492710334985\n",
      "obscene Roc Auc: 0.9937042287431658\n",
      "threat Roc Auc: 0.9951877181162467\n",
      "insult Roc Auc: 0.9882207845446002\n",
      "identity_hate Roc Auc: 0.9909493576496841\n",
      "Result Roc Auc: 0.9910238515324824\n",
      "Test: ROC AUC\n",
      "toxic Roc Auc: 0.9691405532351995\n",
      "severe_toxic Roc Auc: 0.9883079065645375\n",
      "obscene Roc Auc: 0.9867202417152341\n",
      "threat Roc Auc: 0.9831497794641557\n",
      "insult Roc Auc: 0.974094223225878\n",
      "identity_hate Roc Auc: 0.9763974381248572\n",
      "Result Roc Auc: 0.9796350237216437\n",
      "Training time (mins): 2.58\n"
     ]
    }
   ],
   "source": [
    "predictions, targets, models = fit_ensemble(train[\"comment_text\"],\n",
    "                                           train[target_columns],\n",
    "                                           stratifier,\n",
    "                                           pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fd0edbf8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OOF Train ROC AUC: \n",
      "toxic Roc Auc: 0.9852967067740348\n",
      "severe_toxic Roc Auc: 0.9928454229205064\n",
      "obscene Roc Auc: 0.993753486346106\n",
      "threat Roc Auc: 0.9952192116676474\n",
      "insult Roc Auc: 0.9882053067712169\n",
      "identity_hate Roc Auc: 0.9909003199337157\n",
      "Result Roc Auc: 0.9910367424022045\n",
      "OOF Test ROC AUC: \n",
      "toxic Roc Auc: 0.9703555576180001\n",
      "severe_toxic Roc Auc: 0.9860109975833796\n",
      "obscene Roc Auc: 0.9853116219380653\n",
      "threat Roc Auc: 0.9810727926906362\n",
      "insult Roc Auc: 0.9765774621188501\n",
      "identity_hate Roc Auc: 0.9762888290301602\n",
      "Result Roc Auc: 0.9792695434965152\n"
     ]
    }
   ],
   "source": [
    "all_train_preds = np.concatenate(predictions[0])\n",
    "all_test_preds = np.concatenate(predictions[1])\n",
    "all_train_targets = np.concatenate(targets[0])\n",
    "all_test_targets = np.concatenate(targets[1])\n",
    "\n",
    "print(\"OOF Train ROC AUC: \")\n",
    "compute_metric(all_train_targets, all_train_preds);\n",
    "print(\"OOF Test ROC AUC: \")\n",
    "compute_metric(all_test_targets, all_test_preds);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7d861cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred = []\n",
    "for m in models:\n",
    "    fold_test_pred = m.predict_proba(test[\"comment_text\"])\n",
    "    fold_test_pred = np.stack([el[:,1] for el in fold_test_pred],axis=1)\n",
    "    test_pred.append(fold_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "91b9c4b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "toxic Roc Auc: 0.9595593971848475\n",
      "severe_toxic Roc Auc: 0.985053953403857\n",
      "obscene Roc Auc: 0.9743637425419565\n",
      "threat Roc Auc: 0.9848368657308892\n",
      "insult Roc Auc: 0.966043503893582\n",
      "identity_hate Roc Auc: 0.9788025376713337\n",
      "Result Roc Auc: 0.9747766667377444\n"
     ]
    }
   ],
   "source": [
    "compute_metric(\n",
    "    test[target_columns].values, \n",
    "    np.stack(test_pred,axis=0).mean(0)\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3a354057",
   "metadata": {},
   "outputs": [],
   "source": [
    "pygame.mixer.init()\n",
    "pygame.mixer.music.load(\"Ding-sound-effect.mp3\")\n",
    "pygame.mixer.music.play()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2abbb7dd",
   "metadata": {},
   "source": [
    "# Rough preprocessing:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c864a6c",
   "metadata": {},
   "source": [
    "## Ensemble of logistic regressions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35c6b12e",
   "metadata": {},
   "source": [
    "### 1. CountVectorizer, nfolds=5, max_iter=100\n",
    "\n",
    "- Test ROC AUC : **0.9421719642964623**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e942ee7",
   "metadata": {},
   "source": [
    "### 2. CountVectorizer(ngram_range=(1,2), nfolds=5, max_iter=100\n",
    "\n",
    "- Test ROC AUC : **0.9560571239783178**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acfafb2f",
   "metadata": {},
   "source": [
    "### 3. TfidfVectorizer, nfolds=10, max_iter=100\n",
    "\n",
    "- Test ROC AUC : **0.9747766667377444**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12c19a99",
   "metadata": {},
   "source": [
    "### 4. TfidfVectorizer, nfolds=100, max_iter=1000\n",
    "\n",
    "- Test ROC AUC : **0.9751705975515662**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09ceab25",
   "metadata": {},
   "source": [
    "# Stemming"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b7ed636",
   "metadata": {},
   "source": [
    "### 1. TfidfVectorizer, nfolds=10, max_iter=1000\n",
    "\n",
    "- Test ROC AUC : **0.9747772431681904**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4152eac",
   "metadata": {},
   "source": [
    "# Custom preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edf54df3",
   "metadata": {},
   "source": [
    "### 1. TfidfVectorizer, nfolds=10, max_iter=1000\n",
    "\n",
    "- Test ROC AUC : **0.9730420525646767**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b54dfa7",
   "metadata": {},
   "source": [
    "### 2. Sentence transformer\n",
    "\n",
    "- Test ROC AUC : **0.9730434707952297**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ba92da1",
   "metadata": {},
   "source": [
    "# PyTorch RNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "2f9f6eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UniversalRNN(nn.Module):\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        num_embeddings,\n",
    "        out_channels,\n",
    "        rnn_channels=512,\n",
    "        rnn_type=nn.GRU,\n",
    "        n_rnns=1,\n",
    "        bidirectional=True,\n",
    "        average_type=None\n",
    "    ):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.embedding_layer = nn.Embedding(num_embeddings, rnn_channels)\n",
    "        self.rnns = rnn_type(\n",
    "            rnn_channels, \n",
    "            rnn_channels, \n",
    "            bidirectional=bidirectional, \n",
    "            num_layers=n_rnns,\n",
    "            batch_first=True\n",
    "        )\n",
    "        if not (average_type is None or average_type in [\"mean\", \"last\"]):\n",
    "            raise ValueError(f\"{average_type} is nit supported average_type\")\n",
    "        self.average_type = average_type\n",
    "        self.classifier = nn.Linear(\n",
    "            rnn_channels * 2 if bidirectional else rnn_channels, \n",
    "            out_channels, \n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.embedding_layer(x)\n",
    "        x = self.rnns(x)[0]\n",
    "        if self.average_type is None:\n",
    "            x = self.classifier(x)\n",
    "        else:\n",
    "            #[Batch, Time Dimension, Channels]\n",
    "            if self.average_type == \"mean\":\n",
    "                x = x.mean(1)\n",
    "            elif self.average_type == \"last\":\n",
    "                x = x[:,-1,:]\n",
    "            x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "25cb8c43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UniversalRNN(\n",
       "  (embedding_layer): Embedding(128, 512)\n",
       "  (rnns): GRU(512, 512, batch_first=True, bidirectional=True)\n",
       "  (classifier): Linear(in_features=1024, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn_model = UniversalRNN(128, 2)\n",
    "nn_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "bf6ef604",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = get_tokenizer('basic_english')\n",
    "\n",
    "def yield_tokens(data_iter):\n",
    "    for text in data_iter:\n",
    "        yield tokenizer(text)\n",
    "\n",
    "vocab = build_vocab_from_iterator(\n",
    "    yield_tokens(train[\"comment_text\"]), \n",
    "    specials=[\"<unk>\"]\n",
    ")\n",
    "vocab.set_default_index(vocab[\"<unk>\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "58814fda",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextDataset(torch.utils.data.Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        texts,\n",
    "        targets,\n",
    "        dataset_vocab,\n",
    "        dataset_tokenizer,\n",
    "        max_length,\n",
    "        trim_policy=\"random\"\n",
    "    ):\n",
    "        self.targets = targets\n",
    "        self.texts = texts\n",
    "        self.vocab = dataset_vocab\n",
    "        self.tokenizer = dataset_tokenizer\n",
    "        \n",
    "        self.max_length = max_length\n",
    "        if trim_policy not in [\"random\", \"first\"]:\n",
    "            raise ValueError(f\"{trim_policy} is not valid trim_policy\")\n",
    "        self.trim_policy = trim_policy\n",
    "    \n",
    "    def select_text_subsequance(self, input):\n",
    "        if len(input) < self.max_length:\n",
    "            return input + [0] * (self.max_length - len(input))\n",
    "        elif len(input) > self.max_length:\n",
    "            if self.trim_policy == \"random\":\n",
    "                start = np.random.randint(0, len(input) - self.max_length)\n",
    "            elif self.trim_policy == \"first\":\n",
    "                start = 0\n",
    "            return input[start : start + self.max_length]\n",
    "        else: \n",
    "            return input\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        text_ids = self.vocab(self.tokenizer(self.texts[idx]))\n",
    "        # In order to form batch, which is a tensor - we have to get sequnces of same length\n",
    "        text_ids = self.select_text_subsequance(text_ids)\n",
    "        return (\n",
    "            torch.LongTensor(text_ids), \n",
    "            torch.from_numpy(self.targets[idx]).float()\n",
    "        )\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "dd6fd42b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.95 Quantile of N tokens: 125.0\n"
     ]
    }
   ],
   "source": [
    "train_n_tokens = train[\"comment_text\"].apply(lambda x : len(tokenizer(x)))\n",
    "\n",
    "plt.title(\"Train N Tokens Distribution\")\n",
    "train_n_tokens.hist(bins=100)\n",
    "plt.show()\n",
    "\n",
    "max_tokens = np.quantile(train_n_tokens, 0.95)\n",
    "\n",
    "print(f\"0.95 Quantile of N tokens: {max_tokens}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "e1594ebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_torch_dataset = TextDataset(\n",
    "    texts=train[\"comment_text\"].to_list(),\n",
    "    targets=train[target_columns].values,\n",
    "    dataset_vocab=vocab,\n",
    "    dataset_tokenizer=tokenizer,\n",
    "    max_length=max_tokens,\n",
    "    # trim_policy=\"first\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "a0e1d8ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_torch_dataloader = torch.utils.data.DataLoader(\n",
    "    train_torch_dataset,\n",
    "    batch_size=16,\n",
    "    shuffle=True,\n",
    "    drop_last=True,\n",
    "    pin_memory=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "72f5ef75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def torch_loop(\n",
    "    dataloader, \n",
    "    inp_model,\n",
    "    inp_optimizer,\n",
    "    inp_criterion,\n",
    "    mode=\"train\",\n",
    "    device=\"mps\"\n",
    "):\n",
    "    if mode == \"train\":\n",
    "        inp_model.train()\n",
    "    else:\n",
    "        inp_model.eval()\n",
    "    all_predicted_label = []\n",
    "    all_losses = []\n",
    "    all_targets = []\n",
    "    with torch.inference_mode(mode=(mode != \"train\")):\n",
    "        for text, label in tqdm(dataloader):\n",
    "            text, label = text.to(device), label.to(device)\n",
    "            if mode == \"train\":\n",
    "                inp_optimizer.zero_grad()\n",
    "            # 1.1 Compute Forward path\n",
    "            predicted_label = inp_model(text)\n",
    "            # 1.2 Compute Cost function (part of Forward path)\n",
    "            loss = criterion(predicted_label, label)\n",
    "            if mode == \"train\":\n",
    "                # TODO: Is mean a best choice ?\n",
    "                # 2. Compute Backward path\n",
    "                loss.mean().backward()\n",
    "                # TODO: Try gradient clipping \n",
    "                # torch.nn.utils.clip_grad_norm_(model.parameters(), 0.1)\n",
    "                # 3. Apply gradient descent `on steroids` \n",
    "                optimizer.step()\n",
    "                \n",
    "            # Accumulate stats\n",
    "            # We receive logits and we have to transform them into `probs`. That is why sigmoid is used\n",
    "            all_predicted_label.append(torch.sigmoid(predicted_label.detach()).cpu().numpy())\n",
    "            all_losses.append(loss.detach().cpu().numpy())\n",
    "            all_targets.append(label.detach().cpu().numpy())\n",
    "    all_predicted_label = np.concatenate(all_predicted_label)\n",
    "    all_losses = np.concatenate(all_losses)\n",
    "    all_targets = np.concatenate(all_targets)\n",
    "    \n",
    "    return all_predicted_label, all_losses, all_targets\n",
    "\n",
    "def print_losses(input):\n",
    "    for cls_idx, cls_name in enumerate(target_columns):\n",
    "        print(f\"{tgt_col} BCE loss: {input[:,cls_idx].mean()}\")\n",
    "    print(f\"Result BCE loss: {input.mean()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "5380ccbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_model = UniversalRNN(\n",
    "    num_embeddings=len(vocab),\n",
    "    out_channels=len(target_columns),\n",
    "    average_type=\"mean\"\n",
    ").to(\"mps\")\n",
    "\n",
    "# TODO: Read more about different loss funcrions https://pytorch.org/docs/stable/nn.html#loss-functions\n",
    "criterion = torch.nn.BCEWithLogitsLoss(reduction=\"none\")\n",
    "# TODO: Read more about Optimizers https://pytorch.org/docs/stable/optim.html\n",
    "# TODO: Try to tune hyperparameters here\n",
    "optimizer = torch.optim.Adam(nn_model.parameters(), lr=0.001)\n",
    "# TODO: Read more about schedulers https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=1, factor=0.5, min_lr=1e-7, mode=\"max\", verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "b1fdf759",
   "metadata": {},
   "outputs": [],
   "source": [
    "folds_ids = [el for el in stratifier.split(train, train[\"stratified_target\"])]\n",
    "\n",
    "train_torch_dataset = TextDataset(\n",
    "    texts=train.iloc[folds_ids[0][0]][\"comment_text\"].to_list(),\n",
    "    targets=train.iloc[folds_ids[0][0]][target_columns].values,\n",
    "    dataset_vocab=vocab,\n",
    "    dataset_tokenizer=tokenizer,\n",
    "    max_length=max_tokens,\n",
    ")\n",
    "# TODO: Read more about DataLoader : https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader\n",
    "train_torch_dataloader = torch.utils.data.DataLoader(\n",
    "    train_torch_dataset,\n",
    "    batch_size=32,\n",
    "    shuffle=True,\n",
    "    # It is important to drop last batch while training. Why ?\n",
    "    drop_last=True,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "valid_torch_dataset = TextDataset(\n",
    "    texts=train.iloc[folds_ids[0][1]][\"comment_text\"].to_list(),\n",
    "    targets=train.iloc[folds_ids[0][1]][target_columns].values,\n",
    "    dataset_vocab=vocab,\n",
    "    dataset_tokenizer=tokenizer,\n",
    "    max_length=max_tokens,\n",
    "    trim_policy=\"first\"\n",
    ")\n",
    "valid_torch_dataloader = torch.utils.data.DataLoader(\n",
    "    valid_torch_dataset,\n",
    "    batch_size=32,\n",
    "    shuffle=False,\n",
    "    drop_last=False,\n",
    "    pin_memory=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "28215f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "TOKENIZERS_PARALLELISM=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "93d81c7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Epoch 1\n",
      "Train phase\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                  | 0/4487 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "can't multiply sequence by non-int of type 'numpy.float64'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[92], line 21\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# 1.1 Iterate over all train dataset and update model weights\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTrain phase\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 21\u001b[0m train_epoch_labels, train_epoch_losses, train_epoch_targets \u001b[38;5;241m=\u001b[39m \u001b[43mtorch_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdataloader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_torch_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[43m    \u001b[49m\u001b[43minp_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnn_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[43m    \u001b[49m\u001b[43minp_optimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[43m    \u001b[49m\u001b[43minp_criterion\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmps\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m     28\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m# 1.2 Compute and print train metrics\u001b[39;00m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTrain metrics\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[88], line 17\u001b[0m, in \u001b[0;36mtorch_loop\u001b[0;34m(dataloader, inp_model, inp_optimizer, inp_criterion, mode, device)\u001b[0m\n\u001b[1;32m     15\u001b[0m all_targets \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39minference_mode(mode\u001b[38;5;241m=\u001b[39m(mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m)):\n\u001b[0;32m---> 17\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m text, label \u001b[38;5;129;01min\u001b[39;00m tqdm(dataloader):\n\u001b[1;32m     18\u001b[0m         text, label \u001b[38;5;241m=\u001b[39m text\u001b[38;5;241m.\u001b[39mto(device), label\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     19\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/tf/lib/python3.9/site-packages/tqdm/std.py:1195\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1192\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[1;32m   1194\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1195\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[1;32m   1196\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[1;32m   1197\u001b[0m         \u001b[38;5;66;03m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[1;32m   1198\u001b[0m         \u001b[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/tf/lib/python3.9/site-packages/torch/utils/data/dataloader.py:628\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    625\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    626\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    627\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 628\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    629\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    630\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    631\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    632\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/tf/lib/python3.9/site-packages/torch/utils/data/dataloader.py:671\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    669\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    670\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 671\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    672\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    673\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/tf/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py:58\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     56\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     57\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 58\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     60\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/tf/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py:58\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     56\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     57\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 58\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     60\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "Cell \u001b[0;32mIn[74], line 36\u001b[0m, in \u001b[0;36mTextDataset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     34\u001b[0m text_ids \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvocab(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtokenizer(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtexts[idx]))\n\u001b[1;32m     35\u001b[0m \u001b[38;5;66;03m# In order to form batch, which is a tensor - we have to get sequnces of same length\u001b[39;00m\n\u001b[0;32m---> 36\u001b[0m text_ids \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselect_text_subsequance\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext_ids\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[1;32m     38\u001b[0m     torch\u001b[38;5;241m.\u001b[39mLongTensor(text_ids), \n\u001b[1;32m     39\u001b[0m     torch\u001b[38;5;241m.\u001b[39mfrom_numpy(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtargets[idx])\u001b[38;5;241m.\u001b[39mfloat()\n\u001b[1;32m     40\u001b[0m )\n",
      "Cell \u001b[0;32mIn[74], line 23\u001b[0m, in \u001b[0;36mTextDataset.select_text_subsequance\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mselect_text_subsequance\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m     22\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28minput\u001b[39m) \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_length:\n\u001b[0;32m---> 23\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_length\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28minput\u001b[39m) \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_length:\n\u001b[1;32m     25\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrim_policy \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrandom\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "\u001b[0;31mTypeError\u001b[0m: can't multiply sequence by non-int of type 'numpy.float64'"
     ]
    }
   ],
   "source": [
    "# TODO: read this article about sample, batch, epoch differences - https://machinelearningmastery.com/difference-between-a-batch-and-an-epoch/\n",
    "# TODO: Try to train longer \n",
    "n_epochs = 3\n",
    "\n",
    "train_all_epoch_labels = []\n",
    "train_all_epoch_losses = []\n",
    "train_all_epoch_targets = []\n",
    "valid_all_epoch_labels = []\n",
    "valid_all_epoch_losses = []\n",
    "valid_all_epoch_targets = []\n",
    "valid_roc_aucs = []\n",
    "train_roc_aucs = []\n",
    "\n",
    "best_metric = - np.inf\n",
    "best_model_state_dict = None\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    print(f\"Starting Epoch {epoch+1}\")\n",
    "    # 1.1 Iterate over all train dataset and update model weights\n",
    "    print(\"Train phase\")\n",
    "    train_epoch_labels, train_epoch_losses, train_epoch_targets = torch_loop(\n",
    "        dataloader=train_torch_dataloader, \n",
    "        inp_model=nn_model,\n",
    "        inp_optimizer=optimizer,\n",
    "        inp_criterion=criterion,\n",
    "        device=\"mps\",\n",
    "        mode=\"train\"\n",
    "    )\n",
    "    # 1.2 Compute and print train metrics\n",
    "    print(\"Train metrics\")\n",
    "    _, train_roc_auc = comp_metric(\n",
    "        train_epoch_targets, \n",
    "        train_epoch_labels\n",
    "    )\n",
    "    print(\"Train BCE losses\")\n",
    "    print_losses(train_epoch_losses)\n",
    "    # 2.1 Iterate over all valid dataset and compute predictions\n",
    "    print(\"Valid phase\")\n",
    "    valid_epoch_labels, valid_epoch_losses, valid_epoch_targets = torch_loop(\n",
    "        dataloader=valid_torch_dataloader, \n",
    "        inp_model=nn_model,\n",
    "        inp_optimizer=optimizer,\n",
    "        inp_criterion=criterion,\n",
    "        device=\"mps\",\n",
    "        mode=\"eval\"\n",
    "    )\n",
    "    # 2.2 Compute and print valid metrics\n",
    "    print(\"Valid metrics\")\n",
    "    _, valid_roc_auc = comp_metric(\n",
    "        valid_epoch_targets, \n",
    "        valid_epoch_labels\n",
    "    )\n",
    "    print(\"Valid BCE losses\")\n",
    "    print_losses(valid_epoch_losses)\n",
    "    # 3. Update learning rate (if needed)\n",
    "    scheduler.step(valid_roc_auc)\n",
    "    # 4. Save best model\n",
    "    if valid_roc_auc > best_metric:\n",
    "        best_metric = valid_roc_auc\n",
    "        best_model_state_dict = deepcopy(nn_model.state_dict())\n",
    "    # 5. Accumulate all stats  \n",
    "    train_all_epoch_labels.append(train_epoch_labels)\n",
    "    train_all_epoch_losses.append(train_epoch_losses)\n",
    "    train_all_epoch_targets.append(train_epoch_targets)\n",
    "    valid_all_epoch_labels.append(valid_epoch_labels)\n",
    "    valid_all_epoch_losses.append(valid_epoch_losses)\n",
    "    valid_all_epoch_targets.append(valid_epoch_targets)\n",
    "    valid_roc_aucs.append(valid_roc_auc)\n",
    "    train_roc_aucs.append(train_roc_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9abcbff1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d4af58f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a21b3627",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9 (tf)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
