{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "f3819e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import pygame\n",
    "from functools import reduce\n",
    "from tqdm import tqdm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# NLP\n",
    "import re\n",
    "import gensim\n",
    "import nltk\n",
    "import spacy\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "from pymystem3 import Mystem\n",
    "from string import punctuation\n",
    "from spacy.tokenizer import Tokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import tokenize\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Sklearn\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import roc_auc_score, precision_score, recall_score\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import StratifiedKFold, RepeatedStratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "153ae9d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gpu for mac m1\n",
    "mps_device = torch.device(\"mps\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "be7c7c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"../data/jigsaw-toxic-comment-classification-challenge/train.csv\")\n",
    "test = pd.read_csv(\"../data/jigsaw-toxic-comment-classification-challenge/test.csv\")\n",
    "test_labels = pd.read_csv(\"../data/jigsaw-toxic-comment-classification-challenge/test_labels.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "801bd718",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000997932d777bf</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000103f0d9cfb60f</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000113f07ec002fd</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0001b41b1c6bb37e</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0001d958c54c6e35</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                       comment_text  toxic  \\\n",
       "0  0000997932d777bf  Explanation\\nWhy the edits made under my usern...      0   \n",
       "1  000103f0d9cfb60f  D'aww! He matches this background colour I'm s...      0   \n",
       "2  000113f07ec002fd  Hey man, I'm really not trying to edit war. It...      0   \n",
       "3  0001b41b1c6bb37e  \"\\nMore\\nI can't make any real suggestions on ...      0   \n",
       "4  0001d958c54c6e35  You, sir, are my hero. Any chance you remember...      0   \n",
       "\n",
       "   severe_toxic  obscene  threat  insult  identity_hate  \n",
       "0             0        0       0       0              0  \n",
       "1             0        0       0       0              0  \n",
       "2             0        0       0       0              0  \n",
       "3             0        0       0       0              0  \n",
       "4             0        0       0       0              0  "
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "e6ad96c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_columns = [\"toxic\", \"severe_toxic\",\n",
    "                  \"obscene\", \"threat\",\n",
    "                  \"insult\", \"identity_hate\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "0c75b2d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test.merge(test_labels, on=\"id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "0194a92a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00001cee341fdb12</td>\n",
       "      <td>Yo bitch Ja Rule is more succesful then you'll...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0000247867823ef7</td>\n",
       "      <td>== From RfC == \\n\\n The title is fine as it is...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00013b17ad220c46</td>\n",
       "      <td>\" \\n\\n == Sources == \\n\\n * Zawe Ashton on Lap...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00017563c3f7919a</td>\n",
       "      <td>:If you have a look back at the source, the in...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00017695ad8997eb</td>\n",
       "      <td>I don't anonymously edit articles at all.</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                       comment_text  toxic  \\\n",
       "0  00001cee341fdb12  Yo bitch Ja Rule is more succesful then you'll...     -1   \n",
       "1  0000247867823ef7  == From RfC == \\n\\n The title is fine as it is...     -1   \n",
       "2  00013b17ad220c46  \" \\n\\n == Sources == \\n\\n * Zawe Ashton on Lap...     -1   \n",
       "3  00017563c3f7919a  :If you have a look back at the source, the in...     -1   \n",
       "4  00017695ad8997eb          I don't anonymously edit articles at all.     -1   \n",
       "\n",
       "   severe_toxic  obscene  threat  insult  identity_hate  \n",
       "0            -1       -1      -1      -1             -1  \n",
       "1            -1       -1      -1      -1             -1  \n",
       "2            -1       -1      -1      -1             -1  \n",
       "3            -1       -1      -1      -1             -1  \n",
       "4            -1       -1      -1      -1             -1  "
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "2caa5c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "closed_test = test[(test[target_columns] == -1).any(axis=1)].reset_index(drop=True)\n",
    "test = test[~(test[target_columns] == -1).any(axis=1)].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "976a08f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id               0\n",
      "comment_text     0\n",
      "toxic            0\n",
      "severe_toxic     0\n",
      "obscene          0\n",
      "threat           0\n",
      "insult           0\n",
      "identity_hate    0\n",
      "dtype: int64 \n",
      "\n",
      "id               0\n",
      "comment_text     0\n",
      "toxic            0\n",
      "severe_toxic     0\n",
      "obscene          0\n",
      "threat           0\n",
      "insult           0\n",
      "identity_hate    0\n",
      "dtype: int64 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for data in [train, test]:\n",
    "    print(train.isnull().sum(), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "80267740",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train\n",
      "0    0.904156\n",
      "1    0.095844\n",
      "Name: toxic, dtype: float64\n",
      "0    0.990004\n",
      "1    0.009996\n",
      "Name: severe_toxic, dtype: float64\n",
      "0    0.947052\n",
      "1    0.052948\n",
      "Name: obscene, dtype: float64\n",
      "0    0.997004\n",
      "1    0.002996\n",
      "Name: threat, dtype: float64\n",
      "0    0.950636\n",
      "1    0.049364\n",
      "Name: insult, dtype: float64\n",
      "0    0.991195\n",
      "1    0.008805\n",
      "Name: identity_hate, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(\"Train\")\n",
    "for col in target_columns:\n",
    "    print(train[col].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "d94a092a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test\n",
      "0    0.904811\n",
      "1    0.095189\n",
      "Name: toxic, dtype: float64\n",
      "0    0.994264\n",
      "1    0.005736\n",
      "Name: severe_toxic, dtype: float64\n",
      "0    0.942308\n",
      "1    0.057692\n",
      "Name: obscene, dtype: float64\n",
      "0    0.996702\n",
      "1    0.003298\n",
      "Name: threat, dtype: float64\n",
      "0    0.946435\n",
      "1    0.053565\n",
      "Name: insult, dtype: float64\n",
      "0    0.988871\n",
      "1    0.011129\n",
      "Name: identity_hate, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(\"Test\")\n",
    "for col in target_columns:\n",
    "    print(test[col].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "b2de93a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = stopwords.words('english')\n",
    "stop_words.extend(['from', 'subject', 're', 'edu', 'use'])\n",
    "mystem = Mystem()\n",
    "\n",
    "def preprocess(text, stemming=True):\n",
    "    if stemming:\n",
    "        tokens = mystem.lemmatize(text.lower())\n",
    "        tokens = [token for token in tokens if token not in stop_words\\\n",
    "                  and token != \" \"\\\n",
    "                  and token.strip() not in punctuation]\n",
    "    else:\n",
    "        tokens = gensim.utils.simple_preprocess(text)\n",
    "        tokens = [token for token in tokens if (token not in\\\n",
    "                    gensim.parsing.preprocessing.STOPWORDS and \n",
    "                    token not in stop_words)]\n",
    "        \n",
    "    text = \" \".join(tokens)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "2afbda8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collapse_dots(input):\n",
    "    # Collapse sequential dots\n",
    "    input = re.sub(\"\\.+\", \".\", input)\n",
    "    # Collapse dots separated by whitespaces\n",
    "    all_collapsed = False\n",
    "    while not all_collapsed:\n",
    "        output = re.sub(r\"\\.(( )*)\\.\", \".\", input)\n",
    "        all_collapsed = input == output\n",
    "        input = output\n",
    "    return output\n",
    "\n",
    "def process_text(input):\n",
    "    if isinstance(input, str):\n",
    "        input = \" \".join(tokenize.sent_tokenize(input))\n",
    "        input = re.sub(r\"http\\S+\", \"\", input)\n",
    "        input = re.sub(r\"\\n+\", \". \", input)\n",
    "        for symb in [\"!\", \",\", \":\", \";\", \"?\"]:\n",
    "            input = re.sub(rf\"\\{symb}\\.\", symb, input)\n",
    "        input = re.sub(\"[^а-яА-Яa-zA-Z0-9!\\\"#$%&'()*+,-./:;<=>?@[\\\\]^_`{|}~ё]+\", \" \", input)\n",
    "        input = re.sub(r\"#\\S+\", \"\", input)\n",
    "        input = collapse_dots(input)\n",
    "        input = input.strip()\n",
    "        # input = input.lower()\n",
    "    return input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "a93374b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train['comment_text'] = train['comment_text'].apply(preprocess, False)\n",
    "#test['comment_text'] = test['comment_text'].apply(preprocess, False)\n",
    "\n",
    "sent_tr = SentenceTransformer('all-MiniLM-L6-v2', device=\"mps\")\n",
    "train['light_clean_comment_text'] = train['comment_text'].apply(process_text)\n",
    "test['light_clean_comment_text'] = test['comment_text'].apply(process_text)\n",
    "train_embs = sent_tr.encode(train[\"light_clean_comment_text\"].to_list())\n",
    "test_embs = sent_tr.encode(test[\"light_clean_comment_text\"].to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "8fad088e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nmodel = Pipeline([\\n    (\"scaler\", StandardScaler()),\\n    (\"lof_reg\", MultiOutputClassifier(LogisticRegression()))\\n])\\n\\nall_train_pred = model.fit(\\n    train_embs, \\n    train[target_columns]\\n).predict_proba(train_embs)\\nall_train_pred = np.stack([el[:,1] for el in all_train_pred],axis=1)\\ncompute_metric(train[target_columns].values, all_train_pred)\\n'"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "model = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"lof_reg\", MultiOutputClassifier(LogisticRegression()))\n",
    "])\n",
    "\n",
    "all_train_pred = model.fit(\n",
    "    train_embs, \n",
    "    train[target_columns]\n",
    ").predict_proba(train_embs)\n",
    "all_train_pred = np.stack([el[:,1] for el in all_train_pred],axis=1)\n",
    "compute_metric(train[target_columns].values, all_train_pred)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "1a21a92f",
   "metadata": {},
   "outputs": [],
   "source": [
    "FOLDS = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "85dbe8e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "000000    143346\n",
       "100000      5666\n",
       "101010      3800\n",
       "101000      1758\n",
       "100010      1215\n",
       "111010       989\n",
       "101011       618\n",
       "001000       317\n",
       "000010       301\n",
       "111011       265\n",
       "001010       181\n",
       "111000       158\n",
       "100001       136\n",
       "100011       134\n",
       "101110       131\n",
       "100100       113\n",
       "111110        64\n",
       "101111        56\n",
       "000001        54\n",
       "-1            42\n",
       "110000        41\n",
       "101001        35\n",
       "111111        31\n",
       "000011        28\n",
       "000100        22\n",
       "001011        18\n",
       "100110        16\n",
       "110010        14\n",
       "101100        11\n",
       "110100        11\n",
       "Name: stratified_target, dtype: int64"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[\"stratified_target\"] = train[target_columns].apply(\n",
    "    lambda x: reduce(lambda x, y: str(x) + str(y), x), axis=1)\n",
    "\n",
    "small_groups = train[\"stratified_target\"].value_counts()[\n",
    "    train[\"stratified_target\"].value_counts() < FOLDS].index\n",
    "\n",
    "train.loc[train[\"stratified_target\"].isin(small_groups), \"stratified_target\"] = \"-1\"\n",
    "train[\"stratified_target\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "1be9e4c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metric(y_true, y_pred, verbose=True):\n",
    "    assert y_true.shape == y_pred.shape\n",
    "    roc_aucs = [roc_auc_score(y_true[:,i], y_pred[:,i]) for i in range(y_pred.shape[1])]\n",
    "    if verbose:\n",
    "        for metric, col in zip(roc_aucs, target_columns):\n",
    "            print(f\"{col} Roc Auc: {metric}\")\n",
    "        print(f\"Result Roc Auc: {np.mean(roc_aucs)}\")\n",
    "    return roc_aucs, np.mean(roc_aucs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "b72e7091",
   "metadata": {},
   "outputs": [],
   "source": [
    "stratifier = StratifiedKFold(n_splits=FOLDS, random_state=69, shuffle=True)\n",
    "classifier = MultiOutputClassifier(LogisticRegression(max_iter=1000))\n",
    "#vectorizer = CountVectorizer()\n",
    "#vectorizer = CountVectorizer(ngram_range=(1,2))\n",
    "vectorizer = TfidfVectorizer()\n",
    "#spacy_nlp = spacy.load('ru_core_news_md')\n",
    "#vectorizer = CountVectorizer(token_pattern = None, tokenizer=Tokenizer(spacy_nlp.vocab))\n",
    "\n",
    "pipeline = Pipeline([(\"vectorizer\", vectorizer),\n",
    "         (\"classifier\", classifier)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "fd3eeba1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def fit_ensemble(X, y, stratifier, pipeline, verbose=True):\n",
    "    all_train_preds = []\n",
    "    all_test_preds = []\n",
    "    all_train_targets = []\n",
    "    all_test_targets = []\n",
    "    all_models = []\n",
    "    \n",
    "    folds_ids = [el for el in stratifier.split(train, train[\"stratified_target\"])]\n",
    "    \n",
    "    start = time.time()\n",
    "    for fold_id, (train_ids, test_ids) in enumerate(folds_ids):\n",
    "        model = pipeline\n",
    "        model.fit(X.iloc[train_ids], y.iloc[train_ids])\n",
    "\n",
    "        fold_train_preds = model.predict_proba(X.iloc[train_ids])\n",
    "        fold_train_preds = np.stack([el[:,1] for el in fold_train_preds],axis=1)\n",
    "        fold_test_preds = model.predict_proba(X.iloc[test_ids])\n",
    "        fold_test_preds = np.stack([el[:,1] for el in fold_test_preds],axis=1)\n",
    "        fold_train_targets = y.iloc[train_ids].values\n",
    "        fold_test_targets = y.iloc[test_ids].values\n",
    "\n",
    "        if verbose:\n",
    "            print(f\"Fold {fold_id + 1}\")\n",
    "            print(\"Train ROC AUC: \")\n",
    "            compute_metric(fold_train_targets, fold_train_preds)\n",
    "            print(\"Test: ROC AUC\")\n",
    "            compute_metric(fold_test_targets, fold_test_preds)\n",
    "        \n",
    "        all_train_preds.append(fold_train_preds)\n",
    "        all_test_preds.append(fold_test_preds)\n",
    "        all_train_targets.append(fold_train_targets)\n",
    "        all_test_targets.append(fold_test_targets)\n",
    "        all_models.append(model)\n",
    "\n",
    "    stop = time.time()\n",
    "    print('Training time (mins):', np.round((stop - start) / 60, 2))\n",
    "    \n",
    "    return [(all_train_preds, all_test_preds),\n",
    "            (all_train_targets, all_test_targets),\n",
    "            all_models]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "fd033a81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1\n",
      "Train ROC AUC: \n",
      "toxic Roc Auc: 0.9845029581046505\n",
      "severe_toxic Roc Auc: 0.9913963799742392\n",
      "obscene Roc Auc: 0.9926073904226774\n",
      "threat Roc Auc: 0.9955648189274774\n",
      "insult Roc Auc: 0.987452028401751\n",
      "identity_hate Roc Auc: 0.989448024035524\n",
      "Result Roc Auc: 0.9901619333110533\n",
      "Test: ROC AUC\n",
      "toxic Roc Auc: 0.970548941767819\n",
      "severe_toxic Roc Auc: 0.9837125206586694\n",
      "obscene Roc Auc: 0.9809282000242079\n",
      "threat Roc Auc: 0.9821643198390747\n",
      "insult Roc Auc: 0.9762576568997798\n",
      "identity_hate Roc Auc: 0.9822679052382784\n",
      "Result Roc Auc: 0.9793132574046383\n",
      "Fold 2\n",
      "Train ROC AUC: \n",
      "toxic Roc Auc: 0.9847152924116387\n",
      "severe_toxic Roc Auc: 0.9914335438822418\n",
      "obscene Roc Auc: 0.9923387813780559\n",
      "threat Roc Auc: 0.9952905901916151\n",
      "insult Roc Auc: 0.9873535801086503\n",
      "identity_hate Roc Auc: 0.9895608945542577\n",
      "Result Roc Auc: 0.9901154470877432\n",
      "Test: ROC AUC\n",
      "toxic Roc Auc: 0.9683000254029709\n",
      "severe_toxic Roc Auc: 0.9825948545822593\n",
      "obscene Roc Auc: 0.9827627539615127\n",
      "threat Roc Auc: 0.992007569172339\n",
      "insult Roc Auc: 0.9775229537398107\n",
      "identity_hate Roc Auc: 0.97859782726354\n",
      "Result Roc Auc: 0.9802976640204054\n",
      "Fold 3\n",
      "Train ROC AUC: \n",
      "toxic Roc Auc: 0.9845421741696834\n",
      "severe_toxic Roc Auc: 0.9914168558145517\n",
      "obscene Roc Auc: 0.9922269146722706\n",
      "threat Roc Auc: 0.9957363374901754\n",
      "insult Roc Auc: 0.98709407365523\n",
      "identity_hate Roc Auc: 0.9899260141229863\n",
      "Result Roc Auc: 0.9901570616541496\n",
      "Test: ROC AUC\n",
      "toxic Roc Auc: 0.9724638544249348\n",
      "severe_toxic Roc Auc: 0.9806735456099259\n",
      "obscene Roc Auc: 0.9847323658356062\n",
      "threat Roc Auc: 0.9774555394960095\n",
      "insult Roc Auc: 0.9800724361514023\n",
      "identity_hate Roc Auc: 0.9715446647637962\n",
      "Result Roc Auc: 0.9778237343802791\n",
      "Fold 4\n",
      "Train ROC AUC: \n",
      "toxic Roc Auc: 0.9844690825421778\n",
      "severe_toxic Roc Auc: 0.9911526002849042\n",
      "obscene Roc Auc: 0.9923682695120113\n",
      "threat Roc Auc: 0.9956938417374556\n",
      "insult Roc Auc: 0.9872482801132746\n",
      "identity_hate Roc Auc: 0.9895185761124746\n",
      "Result Roc Auc: 0.9900751083837163\n",
      "Test: ROC AUC\n",
      "toxic Roc Auc: 0.973617151846484\n",
      "severe_toxic Roc Auc: 0.9870196716206163\n",
      "obscene Roc Auc: 0.9849203781588124\n",
      "threat Roc Auc: 0.9762890341321715\n",
      "insult Roc Auc: 0.9779901102581381\n",
      "identity_hate Roc Auc: 0.9673918948404304\n",
      "Result Roc Auc: 0.9778713734761088\n",
      "Fold 5\n",
      "Train ROC AUC: \n",
      "toxic Roc Auc: 0.9846283946294837\n",
      "severe_toxic Roc Auc: 0.9918787435664134\n",
      "obscene Roc Auc: 0.99233642488823\n",
      "threat Roc Auc: 0.9953598195200948\n",
      "insult Roc Auc: 0.9874811624789163\n",
      "identity_hate Roc Auc: 0.9894415396175409\n",
      "Result Roc Auc: 0.9901876807834467\n",
      "Test: ROC AUC\n",
      "toxic Roc Auc: 0.9707611226155586\n",
      "severe_toxic Roc Auc: 0.9785706494174489\n",
      "obscene Roc Auc: 0.9847468580296991\n",
      "threat Roc Auc: 0.9826881179822357\n",
      "insult Roc Auc: 0.9727301255265131\n",
      "identity_hate Roc Auc: 0.9696801335930577\n",
      "Result Roc Auc: 0.9765295011940854\n",
      "Fold 6\n",
      "Train ROC AUC: \n",
      "toxic Roc Auc: 0.9844015610442616\n",
      "severe_toxic Roc Auc: 0.991174570159147\n",
      "obscene Roc Auc: 0.9924090123993341\n",
      "threat Roc Auc: 0.9956320148801866\n",
      "insult Roc Auc: 0.9871722398127246\n",
      "identity_hate Roc Auc: 0.9894606053229471\n",
      "Result Roc Auc: 0.9900416672697668\n",
      "Test: ROC AUC\n",
      "toxic Roc Auc: 0.9747355806410144\n",
      "severe_toxic Roc Auc: 0.9866835827616072\n",
      "obscene Roc Auc: 0.9852629753070564\n",
      "threat Roc Auc: 0.9858203951641628\n",
      "insult Roc Auc: 0.9793299976535519\n",
      "identity_hate Roc Auc: 0.9759898406138678\n",
      "Result Roc Auc: 0.98130372869021\n",
      "Fold 7\n",
      "Train ROC AUC: \n",
      "toxic Roc Auc: 0.9844483739204333\n",
      "severe_toxic Roc Auc: 0.9912787166617454\n",
      "obscene Roc Auc: 0.9924235147544221\n",
      "threat Roc Auc: 0.995463602533218\n",
      "insult Roc Auc: 0.9873129228124102\n",
      "identity_hate Roc Auc: 0.9892243528608841\n",
      "Result Roc Auc: 0.9900252472571855\n",
      "Test: ROC AUC\n",
      "toxic Roc Auc: 0.9734517424243936\n",
      "severe_toxic Roc Auc: 0.9841279411210933\n",
      "obscene Roc Auc: 0.9834390991297964\n",
      "threat Roc Auc: 0.9863101598675803\n",
      "insult Roc Auc: 0.9770762224388079\n",
      "identity_hate Roc Auc: 0.9783991971502061\n",
      "Result Roc Auc: 0.9804673936886462\n",
      "Fold 8\n",
      "Train ROC AUC: \n",
      "toxic Roc Auc: 0.9846753225449382\n",
      "severe_toxic Roc Auc: 0.9911802845609602\n",
      "obscene Roc Auc: 0.992325975427821\n",
      "threat Roc Auc: 0.9954247609482818\n",
      "insult Roc Auc: 0.9873790930565299\n",
      "identity_hate Roc Auc: 0.9901268706187019\n",
      "Result Roc Auc: 0.9901853845262055\n",
      "Test: ROC AUC\n",
      "toxic Roc Auc: 0.9731556464131313\n",
      "severe_toxic Roc Auc: 0.9877888441905871\n",
      "obscene Roc Auc: 0.9853784444980438\n",
      "threat Roc Auc: 0.9913351232609225\n",
      "insult Roc Auc: 0.9768039011342325\n",
      "identity_hate Roc Auc: 0.9686860702359847\n",
      "Result Roc Auc: 0.9805246716221504\n",
      "Fold 9\n",
      "Train ROC AUC: \n",
      "toxic Roc Auc: 0.984624184882305\n",
      "severe_toxic Roc Auc: 0.9912551505243203\n",
      "obscene Roc Auc: 0.9924005859353087\n",
      "threat Roc Auc: 0.9952649159689003\n",
      "insult Roc Auc: 0.9873995640459213\n",
      "identity_hate Roc Auc: 0.9894646133545968\n",
      "Result Roc Auc: 0.9900681691185588\n",
      "Test: ROC AUC\n",
      "toxic Roc Auc: 0.9714712037109733\n",
      "severe_toxic Roc Auc: 0.9854470692574376\n",
      "obscene Roc Auc: 0.9844374637923652\n",
      "threat Roc Auc: 0.9846169043428284\n",
      "insult Roc Auc: 0.9768585426161277\n",
      "identity_hate Roc Auc: 0.974069183630332\n",
      "Result Roc Auc: 0.9794833945583442\n",
      "Fold 10\n",
      "Train ROC AUC: \n",
      "toxic Roc Auc: 0.9847292653315846\n",
      "severe_toxic Roc Auc: 0.9913062821408348\n",
      "obscene Roc Auc: 0.9923907674600623\n",
      "threat Roc Auc: 0.9952409803795822\n",
      "insult Roc Auc: 0.9873469223778877\n",
      "identity_hate Roc Auc: 0.989532023093972\n",
      "Result Roc Auc: 0.990091040130654\n",
      "Test: ROC AUC\n",
      "toxic Roc Auc: 0.9695186681810571\n",
      "severe_toxic Roc Auc: 0.9842541305311135\n",
      "obscene Roc Auc: 0.9843054776798036\n",
      "threat Roc Auc: 0.9892764599867359\n",
      "insult Roc Auc: 0.9750124240989446\n",
      "identity_hate Roc Auc: 0.9771237757549682\n",
      "Result Roc Auc: 0.9799151560387706\n",
      "Training time (mins): 3.59\n"
     ]
    }
   ],
   "source": [
    "predictions, targets, models = fit_ensemble(train[\"comment_text\"],\n",
    "                                           train[target_columns],\n",
    "                                           stratifier,\n",
    "                                           pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "fd0edbf8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OOF Train ROC AUC: \n",
      "toxic Roc Auc: 0.984573864715134\n",
      "severe_toxic Roc Auc: 0.9913474357850385\n",
      "obscene Roc Auc: 0.9923828334169036\n",
      "threat Roc Auc: 0.9954670544914722\n",
      "insult Roc Auc: 0.9873241200703835\n",
      "identity_hate Roc Auc: 0.9895692459979138\n",
      "Result Roc Auc: 0.9901107590794743\n",
      "OOF Test ROC AUC: \n",
      "toxic Roc Auc: 0.9717948894728287\n",
      "severe_toxic Roc Auc: 0.9840599373612244\n",
      "obscene Roc Auc: 0.984081260595412\n",
      "threat Roc Auc: 0.9849234127340112\n",
      "insult Roc Auc: 0.9769554932553753\n",
      "identity_hate Roc Auc: 0.9743166589739517\n",
      "Result Roc Auc: 0.9793552753988006\n"
     ]
    }
   ],
   "source": [
    "all_train_preds = np.concatenate(predictions[0])\n",
    "all_test_preds = np.concatenate(predictions[1])\n",
    "all_train_targets = np.concatenate(targets[0])\n",
    "all_test_targets = np.concatenate(targets[1])\n",
    "\n",
    "print(\"OOF Train ROC AUC: \")\n",
    "compute_metric(all_train_targets, all_train_preds);\n",
    "print(\"OOF Test ROC AUC: \")\n",
    "compute_metric(all_test_targets, all_test_preds);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "7d861cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred = []\n",
    "for m in models:\n",
    "    fold_test_pred = m.predict_proba(test[\"comment_text\"])\n",
    "    fold_test_pred = np.stack([el[:,1] for el in fold_test_pred],axis=1)\n",
    "    test_pred.append(fold_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "91b9c4b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "toxic Roc Auc: 0.9586085448623514\n",
      "severe_toxic Roc Auc: 0.9802059623554047\n",
      "obscene Roc Auc: 0.972933273473961\n",
      "threat Roc Auc: 0.9851553757210139\n",
      "insult Roc Auc: 0.9646100405912966\n",
      "identity_hate Roc Auc: 0.9766489655590077\n",
      "Result Roc Auc: 0.9730270270938393\n"
     ]
    }
   ],
   "source": [
    "compute_metric(\n",
    "    test[target_columns].values, \n",
    "    np.stack(test_pred,axis=0).mean(0)\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "3a354057",
   "metadata": {},
   "outputs": [],
   "source": [
    "pygame.mixer.init()\n",
    "pygame.mixer.music.load(\"Ding-sound-effect.mp3\")\n",
    "pygame.mixer.music.play()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2abbb7dd",
   "metadata": {},
   "source": [
    "# Rough preprocessing:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c864a6c",
   "metadata": {},
   "source": [
    "## Ensemble of logistic regressions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35c6b12e",
   "metadata": {},
   "source": [
    "### 1. CountVectorizer, nfolds=5, max_iter=100\n",
    "\n",
    "- Test ROC AUC : **0.9421719642964623**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e942ee7",
   "metadata": {},
   "source": [
    "### 2. CountVectorizer(ngram_range=(1,2), nfolds=5, max_iter=100\n",
    "\n",
    "- Test ROC AUC : **0.9560571239783178**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acfafb2f",
   "metadata": {},
   "source": [
    "### 3. TfidfVectorizer, nfolds=10, max_iter=100\n",
    "\n",
    "- Test ROC AUC : **0.9747766667377444**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12c19a99",
   "metadata": {},
   "source": [
    "### 4. TfidfVectorizer, nfolds=100, max_iter=1000\n",
    "\n",
    "- Test ROC AUC : **0.9751705975515662**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09ceab25",
   "metadata": {},
   "source": [
    "# Stemming"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b7ed636",
   "metadata": {},
   "source": [
    "### 1. TfidfVectorizer, nfolds=10, max_iter=1000\n",
    "\n",
    "- Test ROC AUC : **0.9747772431681904**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4152eac",
   "metadata": {},
   "source": [
    "# Custom preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edf54df3",
   "metadata": {},
   "source": [
    "### 1. TfidfVectorizer, nfolds=10, max_iter=1000\n",
    "\n",
    "- Test ROC AUC : **0.9730420525646767**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b54dfa7",
   "metadata": {},
   "source": [
    "### 2. Sentence transformer\n",
    "\n",
    "- Test ROC AUC : **0.9730434707952297**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ba92da1",
   "metadata": {},
   "source": [
    "# PyTorch RNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "2f9f6eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UniversalRNN(nn.Module):\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        num_embeddings,\n",
    "        out_channels,\n",
    "        rnn_channels=512,\n",
    "        rnn_type=nn.GRU,\n",
    "        n_rnns=1,\n",
    "        bidirectional=True,\n",
    "        average_type=None\n",
    "    ):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.embedding_layer = nn.Embedding(num_embeddings, rnn_channels)\n",
    "        self.rnns = rnn_type(\n",
    "            rnn_channels, \n",
    "            rnn_channels, \n",
    "            bidirectional=bidirectional, \n",
    "            num_layers=n_rnns,\n",
    "            batch_first=True\n",
    "        )\n",
    "        if not (average_type is None or average_type in [\"mean\", \"last\"]):\n",
    "            raise ValueError(f\"{average_type} is nit supported average_type\")\n",
    "        self.average_type = average_type\n",
    "        self.classifier = nn.Linear(\n",
    "            rnn_channels * 2 if bidirectional else rnn_channels, \n",
    "            out_channels, \n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.embedding_layer(x)\n",
    "        x = self.rnns(x)[0]\n",
    "        if self.average_type is None:\n",
    "            x = self.classifier(x)\n",
    "        else:\n",
    "            #[Batch, Time Dimension, Channels]\n",
    "            if self.average_type == \"mean\":\n",
    "                x = x.mean(1)\n",
    "            elif self.average_type == \"last\":\n",
    "                x = x[:,-1,:]\n",
    "            x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "25cb8c43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UniversalRNN(\n",
       "  (embedding_layer): Embedding(128, 512)\n",
       "  (rnns): GRU(512, 512, batch_first=True, bidirectional=True)\n",
       "  (classifier): Linear(in_features=1024, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn_model = UniversalRNN(128, 2)\n",
    "nn_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "bf6ef604",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = get_tokenizer('basic_english')\n",
    "\n",
    "def yield_tokens(data_iter):\n",
    "    for text in data_iter:\n",
    "        yield tokenizer(text)\n",
    "\n",
    "vocab = build_vocab_from_iterator(\n",
    "    yield_tokens(train[\"comment_text\"]), \n",
    "    specials=[\"<unk>\"]\n",
    ")\n",
    "vocab.set_default_index(vocab[\"<unk>\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "58814fda",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextDataset(torch.utils.data.Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        texts,\n",
    "        targets,\n",
    "        dataset_vocab,\n",
    "        dataset_tokenizer,\n",
    "        max_length,\n",
    "        trim_policy=\"random\"\n",
    "    ):\n",
    "        self.targets = targets\n",
    "        self.texts = texts\n",
    "        self.vocab = dataset_vocab\n",
    "        self.tokenizer = dataset_tokenizer\n",
    "        \n",
    "        self.max_length = max_length\n",
    "        if trim_policy not in [\"random\", \"first\"]:\n",
    "            raise ValueError(f\"{trim_policy} is not valid trim_policy\")\n",
    "        self.trim_policy = trim_policy\n",
    "    \n",
    "    def select_text_subsequance(self, input):\n",
    "        if len(input) < self.max_length:\n",
    "            return input + [0] * (self.max_length - len(input))\n",
    "        elif len(input) > self.max_length:\n",
    "            if self.trim_policy == \"random\":\n",
    "                start = np.random.randint(0, len(input) - self.max_length)\n",
    "            elif self.trim_policy == \"first\":\n",
    "                start = 0\n",
    "            return input[start : start + self.max_length]\n",
    "        else: \n",
    "            return input\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        text_ids = self.vocab(self.tokenizer(self.texts[idx]))\n",
    "        # In order to form batch, which is a tensor - we have to get sequnces of same length\n",
    "        text_ids = self.select_text_subsequance(text_ids)\n",
    "        return (\n",
    "            torch.LongTensor(text_ids), \n",
    "            torch.from_numpy(self.targets[idx]).float()\n",
    "        )\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "dd6fd42b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.95 Quantile of N tokens: 267.0\n"
     ]
    }
   ],
   "source": [
    "train_n_tokens = train[\"comment_text\"].apply(lambda x : len(tokenizer(x)))\n",
    "\n",
    "plt.title(\"Train N Tokens Distribution\")\n",
    "train_n_tokens.hist(bins=100)\n",
    "plt.show()\n",
    "\n",
    "print(f\"0.95 Quantile of N tokens: {np.quantile(train_n_tokens, 0.95)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "e1594ebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_tokens = 300\n",
    "\n",
    "train_torch_dataset = TextDataset(\n",
    "    texts=train[\"light_clean_comment_text\"].to_list(),\n",
    "    targets=train[target_columns].values,\n",
    "    dataset_vocab=vocab,\n",
    "    dataset_tokenizer=tokenizer,\n",
    "    max_length=max_tokens,\n",
    "    # trim_policy=\"first\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "614d1859",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: \". Fair use rationale for Image:Wonju.jpg. Thanks for uploading Image:Wonju.jpg. I notice the image page specifies that the image is being used under fair use but there is no explanation or rationale as to why its use in Wikipedia articles constitutes fair use. In addition to the boilerplate fair use template, you must also write out on the image description page a specific explanation or rationale for why using this image in each article is consistent with fair use. Please go to the image description page and edit it to include a fair use rationale. If you have uploaded other fair use media, consider checking that you have specified the fair use rationale on those pages too. You can find a list of 'image' pages you have edited by clicking on the \"\"my contributions\"\" link (it is located at the very top of any Wikipedia page when you are logged in), and then selecting \"\"Image\"\" from the dropdown box. Note that any fair use images uploaded after 4 May, 2006, and lacking such an explanation will be deleted one week after they have been uploaded, as described on criteria for speedy deletion. If you have any questions please ask them at the Media copyright questions page. Thank you. (talk contribs ) . Unspecified source for Image:Wonju.jpg. Thanks for uploading Image:Wonju.jpg. I noticed that the file's description page currently doesn't specify who created the content, so the copyright status is unclear. If you did not create this file yourself, then you will need to specify the owner of the copyright. If you obtained it from a website, then a link to the website from which it was taken, together with a restatement of that website's terms of use of its content, is usually sufficient information. However, if the copyright holder is different from the website's publisher, then their copyright should also be acknowledged. As well as adding the source, please add a proper copyright licensing tag if the file doesn't have one already. If you created/took the picture, audio, or video then the tag can be used to release it under the GFDL. If you believe the media meets the criteria at Wikipedia:Fair use, use a tag such as or one of the other tags listed at Wikipedia:Image copyright tags use. See Wikipedia:Image copyright tags for the full list of copyright tags that you can use. If you have uploaded other files, consider checking that you have specified their source and tagged them, too. You can find a list of files you have uploaded by following [ this link]. Unsourced and untagged images may be deleted one week after they have been tagged, as described on criteria for speedy deletion. If the image is copyrighted under a non-free license (per Wikipedia:Fair use) then the image will be deleted 48 hours after . If you have any questions please ask them at the Media copyright questions page. Thank you. (talk contribs ) \"\n",
      "Text Ids: tensor([  145,   184,   288,    91,    35,    50,    11,    57,   666,    34,\n",
      "          881,    23,     4,    84,   117,    91,    14,    36,    90,  2364,\n",
      "          288,    91,     1,    14,   773,     4,     2,  7672,   288,    91,\n",
      "          368,     3,     9,   258,    75,   341,    87,    20,     2,   125,\n",
      "          674,    37,    10,   522,   666,    34,   881,    16,    84,   212,\n",
      "           17,   125,    14,   419,    32,    11,  1874,    29,   288,    91,\n",
      "            1,    54,   131,     4,     2,   125,   674,    37,     7,    85,\n",
      "           13,     4,   445,    10,   288,    91,   881,     1,    31,     9,\n",
      "           24,   668,    71,   288,    91,   375,     3,   383,  1365,    12,\n",
      "            9,    24,  1940,     2,   288,    91,   881,    20,   153,   126,\n",
      "          170,     1,     9,    43,   149,    10,   177,     6,     8,   125,\n",
      "            8,   126,     9,    24,   570,    41,  1489,    20,     2,    38,\n",
      "          330,   178,    21,    13,    11,  1699,    44,     2,   109,   378,\n",
      "            6,    65,    36,    37,    89,     9,    25,  1655,    14,    19,\n",
      "            3,     7,    92,  2975,   125,    40,     2,  3314,   938,     1,\n",
      "          196,    12,    65,   288,    91,   349,   668,   157,   441,    93,\n",
      "            3,   582,     3,     7,  2435,   118,    39,   666,    53,    22,\n",
      "          147,    59,   685,   157,    56,    24,    66,   668,     3,    23,\n",
      "          925,    20,   391,    16,   265,   123,     1,    31,     9,    24,\n",
      "           65,   245,    54,   216,    97,    44,     2,   375,   254,   245,\n",
      "           37,     1,   140,     9,     1,    21,    49,   515,    19,     1,\n",
      "         6415,   130,    16,   125, 52209,     1,   449,     1,   102,    16,\n",
      "         1325,   125, 52209,     1,   449,     1,     5,   614,    12,     2,\n",
      "          507,     8,    27,   674,    37,   510,   200,     8,    30,  2028,\n",
      "           72,   321,     2,   183,     3,    47,     2,   254,   661,    11,\n",
      "         2142,     1,    31,     9,    96,    18,   463,    17,   507,   210,\n",
      "            3,    92,     9,    53,   133,     4,  2028,     2,  2244,     6,\n",
      "            2,   254,     1,    31,     9,  3384,    13,    40,    10,   373,\n",
      "            3,    92,    10,   178,     4,     2,   373,    40,    62,    13,\n",
      "           33,   523,     3,   765,    29,    10,  6643,     6,    12,   373])\n",
      "Target: tensor([0., 0., 0., 0., 0., 0.])\n",
      "Text Ids length: 300\n"
     ]
    }
   ],
   "source": [
    "doc_idx = 10\n",
    "\n",
    "doc_ids, doc_target = train_torch_dataset[doc_idx]\n",
    "print(\n",
    "    f\"Text: {train_torch_dataset.texts[doc_idx]}\\n\"\n",
    "    f\"Text Ids: {doc_ids}\\n\"\n",
    "    f\"Target: {doc_target}\\n\"\n",
    "    f\"Text Ids length: {len(doc_ids)}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "a0e1d8ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`Text` batch:\n",
      "tensor([[2354,   20,    2,  ...,    0,    0,    0],\n",
      "        [   8,   27,  191,  ..., 8092,    3,   40],\n",
      "        [1216, 1504,  673,  ...,    0,    0,    0],\n",
      "        ...,\n",
      "        [  31,   58,  577,  ...,    0,    0,    0],\n",
      "        [ 183,    1, 4534,  ...,    2,   32,   12],\n",
      "        [   1, 5248,   33,  ...,    0,    0,    0]])\n",
      "`Target` batch:\n",
      "tensor([[0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0.],\n",
      "        [1., 1., 1., 0., 1., 1.],\n",
      "        [1., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "train_torch_dataloader = torch.utils.data.DataLoader(\n",
    "    train_torch_dataset,\n",
    "    batch_size=16,\n",
    "    shuffle=True,\n",
    "    drop_last=True,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "for batch in train_torch_dataloader:\n",
    "    break\n",
    "    \n",
    "print(\n",
    "    f\"`Text` batch:\\n{batch[0]}\\n\"\n",
    "    f\"`Target` batch:\\n{batch[1]}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "72f5ef75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def torch_loop(\n",
    "    dataloader, \n",
    "    inp_model,\n",
    "    inp_optimizer,\n",
    "    inp_criterion,\n",
    "    mode=\"train\",\n",
    "    device=\"mps\"\n",
    "):\n",
    "    if mode == \"train\":\n",
    "        inp_model.train()\n",
    "    else:\n",
    "        inp_model.eval()\n",
    "    all_predicted_label = []\n",
    "    all_losses = []\n",
    "    all_targets = []\n",
    "    with torch.inference_mode(mode=(mode != \"train\")):\n",
    "        for text, label in tqdm(dataloader):\n",
    "            text, label = text.to(device), label.to(device)\n",
    "            if mode == \"train\":\n",
    "                inp_optimizer.zero_grad()\n",
    "            # 1.1 Compute Forward path\n",
    "            predicted_label = inp_model(text)\n",
    "            # 1.2 Compute Cost function (part of Forward path)\n",
    "            loss = criterion(predicted_label, label)\n",
    "            if mode == \"train\":\n",
    "                # TODO: Is mean a best choice ?\n",
    "                # 2. Compute Backward path\n",
    "                loss.mean().backward()\n",
    "                # TODO: Try gradient clipping \n",
    "                # torch.nn.utils.clip_grad_norm_(model.parameters(), 0.1)\n",
    "                # 3. Apply gradient descent `on steroids` \n",
    "                optimizer.step()\n",
    "                \n",
    "            # Accumulate stats\n",
    "            # We receive logits and we have to transform them into `probs`. That is why sigmoid is used\n",
    "            all_predicted_label.append(torch.sigmoid(predicted_label.detach()).cpu().numpy())\n",
    "            all_losses.append(loss.detach().cpu().numpy())\n",
    "            all_targets.append(label.detach().cpu().numpy())\n",
    "    all_predicted_label = np.concatenate(all_predicted_label)\n",
    "    all_losses = np.concatenate(all_losses)\n",
    "    all_targets = np.concatenate(all_targets)\n",
    "    \n",
    "    return all_predicted_label, all_losses, all_targets\n",
    "\n",
    "def print_losses(input):\n",
    "    for cls_idx, cls_name in enumerate(target_columns):\n",
    "        print(f\"{tgt_col} BCE loss: {input[:,cls_idx].mean()}\")\n",
    "    print(f\"Result BCE loss: {input.mean()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "5380ccbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_model = UniversalRNN(\n",
    "    num_embeddings=len(vocab),\n",
    "    out_channels=len(target_columns),\n",
    "    average_type=\"mean\"\n",
    ").to(\"mps\")\n",
    "\n",
    "# TODO: Read more about different loss funcrions https://pytorch.org/docs/stable/nn.html#loss-functions\n",
    "criterion = torch.nn.BCEWithLogitsLoss(reduction=\"none\")\n",
    "# TODO: Read more about Optimizers https://pytorch.org/docs/stable/optim.html\n",
    "# TODO: Try to tune hyperparameters here\n",
    "optimizer = torch.optim.Adam(nn_model.parameters(), lr=0.001)\n",
    "# TODO: Read more about schedulers https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=1, factor=0.5, min_lr=1e-7, mode=\"max\", verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "b1fdf759",
   "metadata": {},
   "outputs": [],
   "source": [
    "folds_ids = [el for el in stratifier.split(train, train[\"stratified_target\"])]\n",
    "\n",
    "train_torch_dataset = TextDataset(\n",
    "    texts=train.iloc[folds_ids[0][0]][\"comment_text\"].to_list(),\n",
    "    targets=train.iloc[folds_ids[0][0]][target_columns].values,\n",
    "    dataset_vocab=vocab,\n",
    "    dataset_tokenizer=tokenizer,\n",
    "    max_length=max_tokens,\n",
    ")\n",
    "# TODO: Read more about DataLoader : https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader\n",
    "train_torch_dataloader = torch.utils.data.DataLoader(\n",
    "    train_torch_dataset,\n",
    "    batch_size=32,\n",
    "    shuffle=True,\n",
    "    # It is important to drop last batch while training. Why ?\n",
    "    drop_last=True,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "valid_torch_dataset = TextDataset(\n",
    "    texts=train.iloc[folds_ids[0][1]][\"comment_text\"].to_list(),\n",
    "    targets=train.iloc[folds_ids[0][1]][target_columns].values,\n",
    "    dataset_vocab=vocab,\n",
    "    dataset_tokenizer=tokenizer,\n",
    "    max_length=max_tokens,\n",
    "    trim_policy=\"first\"\n",
    ")\n",
    "valid_torch_dataloader = torch.utils.data.DataLoader(\n",
    "    valid_torch_dataset,\n",
    "    batch_size=32,\n",
    "    shuffle=False,\n",
    "    drop_last=False,\n",
    "    pin_memory=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "5c58f956",
   "metadata": {},
   "outputs": [],
   "source": [
    "TOKENIZERS_PARALLELISM=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93d81c7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Epoch 1\n",
      "Train phase\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▊                                     | 94/4487 [12:18<10:59:24,  9.01s/it]"
     ]
    }
   ],
   "source": [
    "# TODO: read this article about sample, batch, epoch differences - https://machinelearningmastery.com/difference-between-a-batch-and-an-epoch/\n",
    "# TODO: Try to train longer \n",
    "n_epochs = 3\n",
    "\n",
    "train_all_epoch_labels = []\n",
    "train_all_epoch_losses = []\n",
    "train_all_epoch_targets = []\n",
    "valid_all_epoch_labels = []\n",
    "valid_all_epoch_losses = []\n",
    "valid_all_epoch_targets = []\n",
    "valid_roc_aucs = []\n",
    "train_roc_aucs = []\n",
    "\n",
    "best_metric = - np.inf\n",
    "best_model_state_dict = None\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    print(f\"Starting Epoch {epoch+1}\")\n",
    "    # 1.1 Iterate over all train dataset and update model weights\n",
    "    print(\"Train phase\")\n",
    "    train_epoch_labels, train_epoch_losses, train_epoch_targets = torch_loop(\n",
    "        dataloader=train_torch_dataloader, \n",
    "        inp_model=nn_model,\n",
    "        inp_optimizer=optimizer,\n",
    "        inp_criterion=criterion,\n",
    "        device=\"mps\",\n",
    "        mode=\"train\"\n",
    "    )\n",
    "    # 1.2 Compute and print train metrics\n",
    "    print(\"Train metrics\")\n",
    "    _, train_roc_auc = comp_metric(\n",
    "        train_epoch_targets, \n",
    "        train_epoch_labels\n",
    "    )\n",
    "    print(\"Train BCE losses\")\n",
    "    print_losses(train_epoch_losses)\n",
    "    # 2.1 Iterate over all valid dataset and compute predictions\n",
    "    print(\"Valid phase\")\n",
    "    valid_epoch_labels, valid_epoch_losses, valid_epoch_targets = torch_loop(\n",
    "        dataloader=valid_torch_dataloader, \n",
    "        inp_model=nn_model,\n",
    "        inp_optimizer=optimizer,\n",
    "        inp_criterion=criterion,\n",
    "        device=\"mps\",\n",
    "        mode=\"eval\"\n",
    "    )\n",
    "    # 2.2 Compute and print valid metrics\n",
    "    print(\"Valid metrics\")\n",
    "    _, valid_roc_auc = comp_metric(\n",
    "        valid_epoch_targets, \n",
    "        valid_epoch_labels\n",
    "    )\n",
    "    print(\"Valid BCE losses\")\n",
    "    print_losses(valid_epoch_losses)\n",
    "    # 3. Update learning rate (if needed)\n",
    "    scheduler.step(valid_roc_auc)\n",
    "    # 4. Save best model\n",
    "    if valid_roc_auc > best_metric:\n",
    "        best_metric = valid_roc_auc\n",
    "        best_model_state_dict = deepcopy(nn_model.state_dict())\n",
    "    # 5. Accumulate all stats  \n",
    "    train_all_epoch_labels.append(train_epoch_labels)\n",
    "    train_all_epoch_losses.append(train_epoch_losses)\n",
    "    train_all_epoch_targets.append(train_epoch_targets)\n",
    "    valid_all_epoch_labels.append(valid_epoch_labels)\n",
    "    valid_all_epoch_losses.append(valid_epoch_losses)\n",
    "    valid_all_epoch_targets.append(valid_epoch_targets)\n",
    "    valid_roc_aucs.append(valid_roc_auc)\n",
    "    train_roc_aucs.append(train_roc_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62bb4d83",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7e2d921",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "852961d9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9 (tf)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
