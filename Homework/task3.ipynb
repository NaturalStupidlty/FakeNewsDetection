{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fceba538",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core\n",
    "import time\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#Plotting\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# NLP\n",
    "import gensim\n",
    "import nltk\n",
    "import spacy\n",
    "from pymystem3 import Mystem\n",
    "from string import punctuation\n",
    "from spacy.tokenizer import Tokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "\n",
    "# Sklearn\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score, precision_score, recall_score\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import StratifiedKFold, RepeatedStratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "63d8988f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"../data/propaganda_detection_our_data/fake_detection_df_train.csv\")\n",
    "test = pd.read_csv(\"../data/propaganda_detection_our_data/fake_detection_df_test.csv\")\n",
    "val = pd.read_csv(\"../data/propaganda_detection_our_data/fake_detection_df_val.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "af89b376",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00000_03514</td>\n",
       "      <td>Чернигов прилет во многоэтажку. Говорят русска...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00002_06059</td>\n",
       "      <td>Председатель Следственного комитета РФ Алексан...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00003_08645</td>\n",
       "      <td>Все сейчас массово хотят уехать со Львова.</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00004_00901</td>\n",
       "      <td>«К военным подошли бабушки и попросили убрать ...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00006_06251</td>\n",
       "      <td>С уважение отношусь к Лобаеву, но Владислав, е...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            id                                               text  label\n",
       "0  00000_03514  Чернигов прилет во многоэтажку. Говорят русска...   True\n",
       "1  00002_06059  Председатель Следственного комитета РФ Алексан...   True\n",
       "2  00003_08645         Все сейчас массово хотят уехать со Львова.   True\n",
       "3  00004_00901  «К военным подошли бабушки и попросили убрать ...   True\n",
       "4  00006_06251  С уважение отношусь к Лобаеву, но Владислав, е...   True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "60c238b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 880 entries, 0 to 879\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   id      880 non-null    object\n",
      " 1   text    880 non-null    object\n",
      " 2   label   880 non-null    bool  \n",
      "dtypes: bool(1), object(2)\n",
      "memory usage: 14.7+ KB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2ac8f20e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Target distribution\n",
      "True     0.618182\n",
      "False    0.381818\n",
      "Name: label, dtype: float64 \n",
      "\n",
      "Test Target distribution\n",
      "True     0.560484\n",
      "False    0.439516\n",
      "Name: label, dtype: float64 \n",
      "\n",
      "Validation Target distribution\n",
      "True     0.622047\n",
      "False    0.377953\n",
      "Name: label, dtype: float64 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Train Target distribution\")\n",
    "print(train.label.value_counts(normalize=True), '\\n')\n",
    "\n",
    "print(\"Test Target distribution\")\n",
    "print(test.label.value_counts(normalize=True), '\\n')\n",
    "\n",
    "print(\"Validation Target distribution\")\n",
    "print(val.label.value_counts(normalize=True), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a22ba8d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For simplier preprocessing\n",
    "data = pd.concat([train, val]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8ea7ae4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = stopwords.words('russian')\n",
    "\n",
    "# Improving stopwords\n",
    "ukrainian_stop_words = [\"авжеж\",\"адже\",\"але\",\n",
    "                        \"б\",\"без\",\"був\",\"була\",\n",
    "                        \"були\",\"було\",\"бути\",\n",
    "                        \"більш\",\"вам\",\"вас\",\n",
    "                        \"весь\",\"вздовж\",\"ви\",\n",
    "                        \"вниз\",\"внизу\",\"вона\",\n",
    "                        \"вони\",\"воно\",\"все\",\n",
    "                        \"всередині\",\"всіх\",\n",
    "                        \"від\",\"він\",\"да\",\n",
    "                        \"давай\",\"давати\",\"де\"\n",
    "                        ,\"дещо\",\"для\",\"до\",\n",
    "                        \"з\",\"завжди\",\"замість\",\n",
    "                        \"й\",\"коли\",\"ледве\",\n",
    "                        \"майже\",\"ми\",\"навколо\",\n",
    "                        \"навіть\",\"нам\",\"от\",\n",
    "                        \"отже\",\"отож\",\"поза\",\n",
    "                        \"про\",\"під\",\"та\",\"так\",\n",
    "                        \"такий\",\"також\",\"те\",\n",
    "                        \"ти\",\"тобто\",\"тож\",\n",
    "                        \"тощо\",\"хоча\",\"це\",\n",
    "                        \"цей\",\"чи\",\"чого\",\n",
    "                        \"що\",\"як\",\"який\",\n",
    "                        \"якої\",\"є\",\"із\",\n",
    "                        \"інших\",\"їх\",\"її\"]\n",
    "\n",
    "stop_words.extend(ukrainian_stop_words)\n",
    "stop_words.extend(['это' ,'from', 'subject', 're', 'edu', 'use', 'https', 'link', 'href', 'onclick', '://'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2a229fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "mystem = Mystem()\n",
    "def preprocess(text, stemming=True):\n",
    "    if stemming:\n",
    "        tokens = mystem.lemmatize(text.lower())\n",
    "        tokens = [token for token in tokens if token not in stop_words\\\n",
    "                  and token != \" \"\\\n",
    "                  and token.strip() not in punctuation]\n",
    "    else:\n",
    "        tokens = gensim.utils.simple_preprocess(text)\n",
    "        tokens = [token for token in tokens if (token not in\\\n",
    "                    gensim.parsing.preprocessing.STOPWORDS and \n",
    "                    token not in stop_words)]\n",
    "        \n",
    "    text = \" \".join(tokens)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fb5cfe2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❗️ Кабинет министров Германии заявил, что санкции против энергосектора России не вводились, потому что этим можно причинить больше вреда самим себе \n",
      "\n",
      "❗ ️  кабинет министр германия заявлять санкция против энергосектор россия вводиться причинять вред \n",
      "\n",
      "Украина изолировала Крым не только от воды, но и от других жизненно важных ресурсов. Об этом рассказала в нашем стриме «Летучка» председатель украинской общины Крыма Анастасия Гридчина: «У нас помимо того, что была водная блокада, была энергетическая блокада, когда весь Крым остался без света. Причём это было настолько неожиданно, что меня лично отключение света застало в центре города, моего мужа ― на светофоре: отключился светофор. Это была ночь, и мы все остались в кромешной темноте. Далее последовала продуктовая блокада, когда в Крым не давали пускать продовольствие. Конечно, тогда РФ оперативно среагировала, мы не почувствовали нехватки продуктов, но сам факт». Подписывайтесь на наш канал . @rt_russian \n",
      "\n",
      "украина изолировать крым вода жизненно важный ресурс рассказывать наш стрим  « летучка »  председатель украинский община крым анастасия гридчина : « помимо водный блокада энергетический блокада крым оставаться свет причем настолько неожиданный лично отключение свет заставать центр город муж  ―  светофор отключаться светофор ночь оставаться кромешный темнота далее последовать продуктовый блокада крым давать пускать продовольствие рф оперативно среагировать почувствовать нехватка продукт факт » подписываться наш канал rt russian \n",
      "\n",
      "Продвижение войск ЛНР (синим) и ДНР (тёмно-синим) Кстати между Харьковом и Славянском завязались бои в Бакалее, куда прорвалась колонна русской армии. \n",
      "\n",
      "продвижение войско лнр синий днр темно-синий кстати харьков славянский завязываться бой бакалея прорваться колонна русский армия \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(3):\n",
    "    word = train.loc[random.randrange(train.shape[0])]['text']\n",
    "    print(word, '\\n')\n",
    "    print(preprocess(word), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0dfd357a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['text'] = data['text'].apply(preprocess)\n",
    "test['text'] = test['text'].apply(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9d37d3bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot wordcloud representation\n",
    "\n",
    "#for i in range(2):\n",
    "    #plt.figure(figsize = (20,20)) \n",
    "    #plt.title(\"Fake News\")\n",
    "    #wc = WordCloud(max_words = 500 , width = 800 , height = 400 , stopwords = stop_words).generate(\" \".join(data.loc[data.label == i, \"text\"]))\n",
    "    #plt.imshow(wc, interpolation = 'bilinear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "24236221",
   "metadata": {},
   "outputs": [],
   "source": [
    "#spacy_nlp = spacy.load('ru_core_news_md')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a4e5241d",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "\n",
    "model = Pipeline([\n",
    "        (\"vectorizer\", vectorizer),\n",
    "        #(\"vectorizer\", TfidfVectorizer()),\n",
    "        #(\"vectorizer\", CountVectorizer(token_pattern = None, tokenizer=Tokenizer(spacy_nlp.vocab))),\n",
    "        (\"logistic_regression\", LogisticRegression())\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c018ec61",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data['text']\n",
    "y = data['label']\n",
    "\n",
    "X_test = test['text']\n",
    "y_test = test['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3699ff5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time (mins): 0.08\n"
     ]
    }
   ],
   "source": [
    "# Number of folds in cross validation\n",
    "FOLDS = 100\n",
    "preds = np.zeros(len(X_test))\n",
    "valid_scores={'ROC AUC': [], 'Precision': [], 'Recall': [], 'Time' : []}\n",
    "cross_validation = StratifiedKFold(n_splits=FOLDS, random_state=69, shuffle=True)\n",
    "\n",
    "start = time.time()\n",
    "for fold, (train_idx, val_idx) in enumerate(cross_validation.split(X, y)):\n",
    "    # Get training and validation sets\n",
    "    X_train, X_valid = X[train_idx], X[val_idx]\n",
    "    y_train, y_valid = y[train_idx], y[val_idx]\n",
    "\n",
    "    # Train model\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions and measure ROC AUC\n",
    "    preds += model.predict(X_test)\n",
    "    prediction = model.predict(X_valid)\n",
    "    valid_scores['ROC AUC'] = roc_auc_score(y_valid, prediction)\n",
    "    valid_scores['Precision'] = precision_score(y_valid, prediction)\n",
    "    valid_scores['Recall'] = recall_score(y_valid, prediction)\n",
    "stop = time.time()\n",
    "\n",
    "valid_scores['Time'] = np.round((stop - start) / 60, 2)\n",
    "print('Training time (mins):', np.round((stop - start) / 60, 2))\n",
    "preds = preds / (FOLDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "36fa0602",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ROC AUC': 0.875,\n",
       " 'Precision': 0.8571428571428571,\n",
       " 'Recall': 1.0,\n",
       " 'Time': 0.08}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show results\n",
    "valid_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54e3aac1",
   "metadata": {},
   "source": [
    "## Simple preprocessing:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2905f8e9",
   "metadata": {},
   "source": [
    "1. Logistic regression + spacy tokenizer + improved stopwords:\n",
    "(StratifiedKFold, 10 folds)\n",
    "\n",
    "- **ROC AUC score** : 0.5526315789473684\n",
    "- **Precision** : 0.6458333333333334\n",
    "- **Recall** : 1.0\n",
    "- **Time** : 0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c2b0877",
   "metadata": {},
   "source": [
    "2. Logistic regression + TfidfVectorizer + improved stopwords:\n",
    "(StratifiedKFold, 10 folds)\n",
    "\n",
    "- **ROC AUC score** : 0.5526315789473684\n",
    "- **Precision** : 0.6458333333333334\n",
    "- **Recall** : 1.0\n",
    "- **Time** : 0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f209180",
   "metadata": {},
   "source": [
    "3. Logistic regression + CountVectorizer:\n",
    "(StratifiedKFold, 10 folds)\n",
    "\n",
    "- **ROC AUC score** : 0.7058573853989812\n",
    "- **Precision** : 0.7692307692307693\n",
    "- **Recall** : 0.8064516129032258\n",
    "- **Time** : 0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9075d4d1",
   "metadata": {},
   "source": [
    "4. Logistic regression + CountVectorizer + improved stopwords:\n",
    "(StratifiedKFold, 10 folds)\n",
    "\n",
    "- **ROC AUC score** : 0.7300509337860781\n",
    "- **Precision** : 0.7794117647058824\n",
    "- **Recall** : 0.8548387096774194\n",
    "- **Time** : 0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7fbb61a",
   "metadata": {},
   "source": [
    "5. Logistic regression + CountVectorizer + improved stopwords:\n",
    "(StratifiedKFold, 100 folds)\n",
    "\n",
    "- **ROC AUC score** : 0.75\n",
    "- **Precision** : 0.75\n",
    "- **Recall** : 1.0\n",
    "- **Time** : 0.17"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32190119",
   "metadata": {},
   "source": [
    "6. Logistic regression + CountVectorizer + improved stopwords:\n",
    "(RepeatedStratifiedKFold, 100 folds)\n",
    "\n",
    "- **ROC AUC score** : 0.8333333333333333\n",
    "- **Precision** : 1.0\n",
    "- **Recall** : 0.6666666666666666\n",
    "- **Time** : 1.68"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e358bdc",
   "metadata": {},
   "source": [
    "## Words stemming:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cec7244",
   "metadata": {},
   "source": [
    "Logistic regression + CountVectorizer + improved stopwords:\n",
    "(StratifiedKFold, 100 folds)\n",
    "\n",
    "- **ROC AUC score** : 0.875\n",
    "- **Precision** : 0.8571428571428571\n",
    "- **Recall** : 1.0\n",
    "- **Time** : 0.07"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf68e7cf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9 (tf)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
